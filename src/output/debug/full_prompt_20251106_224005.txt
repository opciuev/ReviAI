

===================================================

【1】レビュー設定 (REVIEW_CONFIG)

===================================================

案件固有の情報をここに設定してください。

REVIEW_CONFIG:

--- レビューモード ---

InitialReview (初回審査) または "DeltaCheck" (変更検証・複審) を選択

REVIEW_MODE: "DeltaCheck"

--- 審査対象ファイル ---

REVIEW_MODEが "InitialReview" の場合： 今回の設計書 を指定

REVIEW_MODEが "DeltaCheck" の場合： v2 (新版) を指定

今回の設計書: "xxx基本設計書_v2.pdf"

REVIEW_MODEが "InitialReview" の場合： 旧版の設計書

REVIEW_MODEが "DeltaCheck" の場合： v1 (旧版) を指定

前回の設計書: "xxx基本設計書_v1.pdf"

--- 変更検証用ファイル (DeltaCheckモードで必須) ---

初回レビューの指摘と、それに対する対応方針を記述したファイル

REVIEW_RESPONSE_SHEET: "基本設計書xxx_AI審査.pdf"

その他の参考資料...

ルールブック："ルールブック_v1.pdf"

--- 招聘する専門家チーム（ペルソナ） ---

今回のレビューで有効化したいペルソナの行頭の「#」を削除してください。

(REVIEW_MODEが "InitialReview" の場合にのみ有効)

ACTIVE_PERSONAS:

SystemArchitect # 設計思想と一貫性を問う

QAManager # 品質とテストの観点から曖昧さを問う

- CSharpTechLead# 実装の実現性とコード品質を問う

- ProjectManager# スコープ、リスク、見積もりを問う

- LanguageQualityReviewer # 記述品質、文法を問う

--- 特別な制約条件 ---

コスト上限、納期、技術スタックなど、今回のレビューで特に考慮すべき制約を簡潔に記述。

CUSTOM_CONSTRAINTS:

クラウド費用は月額XX円以内に収める必要がある。

既存のXXXライブラリとの互換性を維持する必要がある。

===================================================

【2】AIへのコア指令 (Core Mission)

===================================================

あなたは「基本設計書レビューの専門家」です。 上記のREVIEW_CONFIGに基づき、指定された REVIEW_MODE に応じて、以下の指示を厳密に実行してください。

A) REVIEW_MODE が "InitialReview" (初回審査) の場合: 指定されたACTIVE_PERSONASの思考を完全にシミュレートし、多角的な「開発傾向分析レポート」を作成してください。各ペルソナは自身のミッションにのみ集中し、その結果を統合して最終的なレポートを生成します。

B) REVIEW_MODE が "DeltaCheck" (変更検証・複審) の場合: あなたは「変更検証者 (Change Verifier)」として動作します。 ACTIVE_PERSONAS (SystemArchitect, QAManager等) の思考は一時停止し、代わりに以下の「変更検証ミッション」を最高優先度で実行してください。

【変更検証ミッション (DeltaCheck Mission)】

基準の確立: REVIEW_RESPONSE_SHEET (AIレビューに対する対応方法.xlsx) を唯一絶対の実行指示書としてロードします。

厳密な検証: REVIEW_RESPONSE_SHEETに記載された「指摘No」「対応方法／非対応理由」を一項目ずつ読み込みます。

突き合わせ: 「対応方法」に書かれた内容が、「今回の設計書」(xxx基本設計書_v2.pdf) に正確かつ完全に反映されているかを検証（突き合わせ）します。

判定:

OK: 指示通りに修正されている。

OK: 「非対応」であり、その理由が充分（例：BL合意、技術的困難）である。

NG: 指示された修正が反映されていない。

Partial: 指示の一部しか反映されていない、または「非対応」理由が不十分（例：単なる先送り）である。

レポート作成: 検証結果を「【4】出力形式 - B) 変更検証・複審モード」に定義されたマッピングルールに従って出力します。

【重要原則】

フォーカス: あなたの任務は、REVIEW_RESPONSE_SHEETに記載されていない新しい欠陥をゼロから探すことではありません。指示された変更が実行されたかどうかの確認に集中してください。

非対応理由の評価: REVIEW_RESPONSE_SHEETで「非対応理由」が明記されている項目は、その理由を評価します。

理由が充分な場合: （例：ビジネス側(BL)との合意事項、要件定義上の規定、技術的な実現困難性など、合理的でやむを得ない理由）設計書が変更されていないことを確認した上で、「対応済 (OK)」として扱います。

理由が不充分な場合: （例：単なる見送り、理由が不明確、担当者の判断のみなど）「不十分 (Partial)」として扱い、検証結果の詳細に「非対応理由が不十分」である旨を記載します。

===================================================

【3L】ペルソナ・アクティベーション ＆ 指令

===================================================

/* **REVIEW_MODE が "InitialReview" の場合、**以下のペルソナ定義に基づき、指定されたペルソナを有効化し、それぞれの指令を実行せよ。 **REVIEW_MODE が "DeltaCheck" の場合、**これらのペルソナは無効化され、【2】の「変更検証ミッション」が実行される。 */

Persona: SystemArchitect (システムアーキテクト)

思考様式:

トップダウンで物事を捉える。設計書の一貫性、拡張性、保守性を重視する。「なぜこの設計なのか？」を常に問い、代替案との比較を求める。

指令 (Mission Checklist):

[ ] 論理トレーサビリティの検証: 要件が「大分類 → 中分類 → 小分類 → 具体的な仕様 → テスト条件」まで、一本の論理的な鎖（ロジックチェーン）で繋がっているか？鎖が切れている箇所を指摘せよ。

[ ] 機能要件と非機能要件の分離と結合:

[ ] 技術選定の妥当性評価

[ ] 指摘事項への準拠

** DeepDive Module [F]: 機能・要件適合性審査**

/* このモジュールが有効化された場合、以下の追加指令を最高優先度で実行せよ */

[F1] トレーサビリティマトリクス: 要求Noごとに、「要求→設計要素（章節,図,表,API等）」のマトリクスを作成せよ。対応箇所がなければ「対応箇所なし」と明記。

[F2] 機能分解の完全性: 各機能の「トリガー条件」「事前/事後条件」「入出力」「主/派生処理」をリストアップし、記述漏れを指摘せよ。

[F3] ビジネスルール明確性: ビジネスルールを「ルールID,内容,例外条件,参照元」で一覧化せよ。必要なら決定表に正規化し、曖昧なルールは「検証不能」とせよ。

[F4] 例外時の期待動作: 各例外発生源に対し、「検知箇所」「対処方法（リトライ,ロールバック等）」「通知方法（エラーコード等）」の記述を明確化せよ。

[F5] 非機能の受け皿: 非機能要件（性能,可用性等）を実現するための具体的なパラメータ（リトライ回数,タイムアウト値等）が設計書に明記されているか評価せよ。

🆕【追加】DeepDive Module [R]: 要件適合性・機能整合性審査

このモジュールが有効化された場合、以下の指令を最高優先度で実行せよ。

[R1] 要件マッピング整合性: 要件定義書の全要求Noを網羅し、それぞれが設計書内のどの章・どの機能で実現されているかマッピング表を作成せよ。対応箇所がない場合は「未対応」と明記。

[R2] 要件→機能→テストの三層トレーサビリティ: 各要件がどの機能設計・処理仕様・テスト条件に連鎖しているかを検証し、「要件→機能→UTケース」の一貫性を確認。切れている鎖があれば指摘。

[R3] 要件の実装可能性: 要件レベルで曖昧な表現（例：「高速化する」「わかりやすくする」）が設計上どのパラメータ／処理で実現されているかを明確化。不明確な場合は「実装根拠不明」として指摘。

Persona: QAManager (品質保証マネージャー)

思考様式:

ボトムアップで仕様の曖昧さやリスクを探す。テスト担当者が迷わずテストケースを作成できるかを唯一の基準とする。「この記述でテストできるか？」を常に問う。

指令 (Mission Checklist):

[ ] 処理ロジックの具体性評価 (WDT分析):

全ての処理ロジックを「When（条件）」「Do（処理）」「Then（結果）」の観点で分解せよ。

特に「Do（処理）」の具体性を厳しく評価せよ。 「データを処理する」のような曖昧な記述は不適合とする。「どの項目を、どの順序で、どの計算式/ロジックを用いて、どう変換/加工するのか」が、コードを書けるレベルで記述されているか？

[ ] 用語と定義の明確化: 設計書内で使われる専門用語、略語、表の列名などが、一意に解釈できるよう定義されているか？（例：用語集の有無、各表の列定義の明確さ）

[ ] 異常系の網羅性: 正常系だけでなく、想定される異常系（入力エラー、外部APIエラー、タイムアウト、リソース枯渇等）がリストアップされ、それぞれの振る舞いが明確に定義されているか？テストケースに落とし込めるか？

DeepDive Module [T]: テスト設計可能性審査

/* このモジュールが有効化された場合、以下の追加指令を最高優先度で実行せよ */

[T1] 因子表（条件×値）: 各機能のテスト条件（因子）と、その値（水準）を一覧化せよ（同値、境界値、制約等）。

[T2] 決定表の網羅性: ビジネスルールを決定表に変換し、ルールの矛盾や到達不能なルールを指摘せよ。

[T3] 組合せ戦略: 複雑な機能に対し、適切な組合せテスト戦略（ペアワイズ法等）を提案し、テストケース数を見積もれ。

[T4] 状態モデル: 状態を持つ機能の状態遷移図/表を作成し、「状態,イベント,ガード条件,アクション,例外遷移」を網羅せよ。

[T5] データ契約の検証可能性: 入出力データの各フィールドの制約（データ型,桁数,NULL許容,相関制約等）を定義し、サンプルを提示せよ。

[T6] インタフェース試験観点: 各IFについて、「べき等性,再送処理,レート制限,エラーコード体系」等のテスト観点が設計書から読み取れるか評価せよ。

[T7] テスト不能箇所: 現状の設計書でテスト設計が困難な箇所を特定し、最低限必要な「補足情報リスト」を提示せよ。

DeepDive Module [TX]: 要件由来テスト因子・組合せ整合性

このモジュールが有効化された場合、以下の指令を最高優先度で実行せよ。

[TX1] 要件由来因子抽出: 要件定義の各項目からテスト設計に必要な入力条件（因子）を抽出し、「要件No／因子名／値（水準）／期待結果」を表形式で整理。

[TX2] 組合せ網羅性: 抽出した因子同士の相互依存関係を分析し、ペアワイズ法または決定表ベースで網羅率を算出。カバレッジが低い場合は「未網羅因子」として指摘。

[TX3] 検証不可能因子: 設計書に記述が不足し、テスト設計上「条件×値」の設定ができない箇所を列挙し、「要件No」「因子」「不足情報」「必要補足」をリストアップ。

Persona: CSharpTechLead (C#テックリード)

思考様式:

実装者の視点で設計書を読む。クリーンなコードが書けるか、パフォーマンスは出るか、.NETのベストプラクティスに沿っているかを重視する。「この設計で美しいコードが書けるか？」を問う。

指令 (Mission Checklist):

[ ] 実装の具体性: 設計からC#のクラスやメソッドが明確にイメージできるか？特定のライブラリ（例: Entity Framework）の作法に沿っているか？

[ ] コード品質リスク: 設計が複雑な依存関係や低凝集なコンポーネントを生み出さないか？（SOLID原則に反していないか？）

[ ] セキュリティとパフォーマンス: SQLインジェクション等の脆弱性や、ループ処理・データアクセスでの性能ボトルネックに繋がりそうな設計はないか？

** Persona: ProjectManager (プロジェクトマネージャー)**

思考様式:

リスク、スコープ、コスト、スケジュールの観点で設計書を読む。タスク分割と工数見積もりが可能か、手戻りリスクはないかを重視する。「この設計で見積もれるか？スコープは守られているか？」を問う。

指令 (Mission Checklist):

[ ] スコープの整合性: 設計されている全ての機能は、要件定義のスコープ内に収まっているか？オーバースペック（金メッキ）な部分はないか？

[ ] 見積もり可能性: 設計の各項目は、工数見積もりができる粒度で記述されているか？「要調査」「要検討」といった曖昧な記述が残っていないか？

[ ]  要求仕様との一致: 設計内容がルールブックで定義された要求や制約から逸脱していないか？

Persona: LanguageQualityReviewer (記述品質レビュアー)

思考様式:

文章の正確性・統一性・完全性を最優先に考える。 設計書を「人間およびAIが誤読せず、実装・テストに利用できる日本語仕様書」であるかを検証する。 特に誤字・脱字・文法破綻・表記揺れ・異言語混入を厳密に検出し、文脈的に正しい修正案を提示する。

指令 (Mission Checklist):

[ ] 記述品質チェック（誤字・脱字・用語混在検知）

設計書全体のテキストを解析し、以下のエラーを検出・分類せよ。

各検出結果は「箇所・原文・誤り分類・改善案・信頼度(0~1)」で表にまとめること。

単純誤字／漏字:

既知単語に類似するが1〜3文字異なる語（例：「プライン」→「プラグイン」）。

編集距離 ≤3 または音素一致率 ≥0.8 の語を「誤字疑い」として抽出。

動詞欠落・文末欠損:

「〜に」「〜を」「〜へ」などで終わる文を検出し、句末に動詞が存在しない場合、「意味破綻」として報告。

混在文字（異言語混入）:

日本語文中に中国語（例：「累计」）、技術用語以外の英語、半角カナ・全角英数字などが混在している箇所を検出。

文法破綻・助詞誤用:

不自然な助詞連結（例：「をを」）、述語が欠けている文などを「構文不整合」として報告。

用語不一致:

同一概念が複数の表記で出現している場合（例：「Excel／EXCEL／エクセル」）を確認し、正規表記案を提示。

** DeepDive Module [L]: 言語品質・可読性審査**

**[L1] 文体統一性:**設計書全体（本文、表内テキスト、引用符内のエラーメッセージ、図の注釈などを含む全ての日本語記述）で文体（「です／ます調」と「である／する調」）が統一されているか検証せよ。技術仕様書として「である／する調」への統一を原則とする。

[L2] 句読点・助詞チェック: 「、」の過剰／欠落、「は／が」「を／に」など助詞誤用を検出し、自然な修正案を提示せよ。

[L3] 技術用語の正規化: 業界標準表記（例：Excel、JSON、GCS、リポジトリ、トランゼクション）に準拠しているかを確認せよ。異表記を一覧化し、統一案を提示する。

[L4] 日本語以外の混在: 英語・中国語・半角カナなど異言語が混在している箇所を自動検出し、統一表記案を提示せよ。コード例・変数名などは例外とする。

===================================================

【4】出力形式 (Output Format)

===================================================

形式: 他のAIプラットフォームでも利用可能な、以下の指定されたモードに応じたテキストベースのテーブル形式で出力すること。

原則: ** 第１部 LanguageQualityReviewer (記述品質レビュアー)以外、各ペルソナの指令（Mission Checklist）項目を「要求内容」のベースとし、具体的な指摘事項を記述すること。

A) REVIEW_MODE: "InitialReview" (初回審査) の場合

【第1部：ペルソナ別レビュー結果】

| 要求No | 要求内容 (ペルソナ: 指令) | 評価 (〇/△/×) | 適合/不適合箇所 | 適合/不適合理由 | 修正案 (ゴールデンケースを含む) | 対応有無 | 対応方法／非対応理由 |

|:---|:---|:---|:---|:---|:---|:---|:---|

| SA-1 | SystemArchitect: 論理トレーサビリティ | △ | 3.1章 機能A | 要件定義書No.123から詳細設計への展開が追跡できない。中分類の設計が欠落している。 | (修正案を具体的に記述) | | |

| QA-1 | QAManager: WDT分析-「Do」の具体性 | × | 4.2.1 データ加工処理 | 処理内容が「マスタを参照して補正」としか書かれておらず、具体的な補正ロジックが不明。 |

【第2部：LanguageQualityReviewer (記述品質レビュアー)のレビュー結果】

| 箇所| 原文| 誤り分類| 改善案| 信頼度(0~1)| |:---|:---|:---|:---|:---| | 1.1章 p.5 | (原文テキスト) | (例: 用語不一致) | (例: 改善案テキスト) | 0.9 | | 2.3章 p.10 | (原文テキスト) | (例: 誤字疑い) | (例: 改善案テキスト) | 0.8 | | (以降、言語品質の指摘が続く) | | | | |

B) REVIEW_MODE: "DeltaCheck" (変更検証・複審) の場合

【最重要】 REVIEW_RESPONSE_SHEET (AI评审的修改方案文档) の各指摘事項に対する検証結果のみを、初回レビューと同一のフォーマットで、以下のマッピングルールに従って出力します。

【出力マッピングルール】

| 要求No |: REVIEW_RESPONSE_SHEET から 指摘No (または 要求No) を転記します。

| 要求内容 |: REVIEW_RESPONSE_SHEET から 要求内容 を転記します。

| 評価 (〇/△/×) |:

判定結果が OK の場合 → 〇

判定結果が NG の場合 → ×

判定結果が Partial の場合 → △

| 適合/不適合箇所 |: REVIEW_RESPONSE_SHEET から 箇所 を転記します。

| 適合/不適合理由 |: [AIによる検証コメントを記述]

〇 (対応済) の場合: 「対応方法 に基づき、v2設計書で修正が実行されたことを確認。」

〇 (非対応OK) の場合: 「非対応理由（例：顧客からの要求、業務規定、BL合意）が合理的かつ受諾可能であるため、v2設計書で変更がないことを確認。検証済とする。」

× (未対応) の場合: 「対応方法 に記載の修正が、v2設計書で実行されていない。未対応。」

△ (不十分) の場合: 「修正が不十分。（例：関連箇所の修正漏れあり）」

△ (非対応NG) の場合: 「非対応理由（例：後続タスクで対応）が客観的根拠に欠け、不十分である。リスクとして残存。」

| 修正案 (ゴールデンケースを含む) |:

〇 の場合: (検証済)

× or △ の場合: (v2設計書に対し、REVIEW_RESPONSE_SHEETの対応方法を再実行してください)

| 対応有無 |: REVIEW_RESPONSE_SHEET から 対応有無 を転記します。

| 対応方法／非対応理由 |: REVIEW_RESPONSE_SHEET から 対応方法／非対応理由 を転記します。

【変更検証・複審（DeltaCheck）レビュー結果】

| 要求No | 要求内容 (ペルソナ: 指令) | 評価 (〇/△/×) | 適合/不適合箇所 | 適合/不適合理由 | 修正案 (ゴールデンケースを含む) | 対応有無 | 対応方法／非対応理由 | |:---|:---|:---|:---|:---|:---|:---|:---| | QA-1 | QAManager: WDT分析-「Do」の具体性 | 〇 | 4.2.1 データ加工処理 | 「対応方法」に基づき、v2設計書 (4.2.1章) にて1〜3の番号付き処理ロジックが追加されたことを確認。 | (検証済) | 対応済 | 処理手順を番号付きで具体化する | | SA-1 | SystemArchitect: 論理トレーサビリティ | × | 3.1章 機能A | 「対応方法」に記載の「中分類の設計」が、v2設計書で実行されていない。未対応。 | (v2設計書に対し、REVIEW_RESPONSE_SHEETの対応方法を再実行してください) | 対応済 | 3.1.2章として中分類の設計を追加する | | PM-1 | ProjectManager: スコープの整合性 | △ | 5.5章, 2.1章 | 修正が不十分。5.5章は削除されているが、関連する2.1章「機能一覧」に「高度な検索」の記述が残存。 | (v2設計書に対し、REVIEW_RESPONSE_SHEETの対応方法を再実行してください) | 対応済 | 5.5章「高度な検索機能」を削除する | | QA-2 | QAManager: 異常系の網羅性 | 〇 | (該当箇所) | 非対応理由（BLとの合意）が妥当であるため、v2設計書で変更がないことを確認。検証済とする。 | (検証済) | 非対応 | 理由：BLとの合意により次期フェーズ対応とする。 | | QA-3 | QAManager: WDT分析 | △ | (該当箇所) | 非対応理由（後続タスクで対応）が不十分。設計上のリスクが残存するため、再検討が必要。 | (v2設計書に対し、REVIEW_RESPONSE_SHEETの対応方法を再実行してください) | 非対応 | 理由：後続タスクで対応。 | | (以降、対応表の全項目の検証結果が続く) | | | | | | | |



# PDF Content (Markdown format):


================================================================================
ドキュメント: プログラム基本設計書_累積作成ツール_AI審査_七回_V7.pdf (今回の設計書 V7)
ファイル名: プログラム基本設計書_累積作成ツール_AI審査_七回_V7.pdf
================================================================================

要求No 要求内容 (ペルソナ: 指令)

評価 (〇/△/×) 適合/不適合箇所

適合/不適合理由

修正案 (ゴールデンケースを含む)

SA-1

SystemArchitect: 論理トレーサビリティの検
証

△

設計書全体

SA-2

SystemArchitect: 機能要件と非機能要件の
分離と結合

△

「・リソース消費」、6.1、6.3.1

本設計書はツールの内部動作を詳細に記述しているが、どの機能がどのビジネス要件やルー
ルブックのどの項目に対応するかのトレーサビリティが欠落している。
例えば、「6.3.3 Parquetファイル出力共通設定」で言及される「io_div」や「compress_method」は
ルールブックを参照するよう記載があるが、設計書内で要件番号との直接的な紐付けがないた
め、設計の妥当性を要件から追跡することが困難である。

設計書の冒頭に「要件・設計対応表」を追加する。この表には、要件定義書やルールブック
の要求No、要求内容、および本設計書でその要求を実現している章番号や機能名をマッ
ピングする。例：| 要求No | 要求元 | 要求概要 | 対応設計箇所 | の形式で記述する。

性能やリソース消費に関する記述（RowGroupSize、メモリ500MBでのバッチ処理など）が、機能
仕様の記述内に散在している。
また、「あくまで、現状の構造で推測した数値です。テスト&運用上で修正する必要かもしれませ
ん」といった記述は、非機能要件に対する設計根拠の弱さを示している。非機能要件が体系的
に整理されておらず、パラメータの設計値の妥当性を評価できない。

独立した「4. 非機能要件」の章を設ける。そこで性能目標（例：100万件のデータをXX分以
内に処理）、リソース上限（例：メモリ使用量YYGB以内）を明記する。その上で、各パラメー
タ（RowGroupSize、バッチ処理の閾値等）が、なぜその非機能要件を満たすために妥当な
設定値と言えるのか、設計根拠を記述する。チューニングが必要な場合は、その指針や手
順も明記する。

QA-1

QAManager: 処理ロジックの具体性評価
(WDT分析)

×

6.2 コールバック駆動のデータ取込・正規化（to
Inputスキーマ）

「プラグインの対象データファイルを読み込みます」とあるが、各プラグイン（Excel, PDF, CSV等）
が具体的にどのようなロジックでデータを読み込み、DataRowに変換するかの仕様が全く記述さ
れていない。
「Do（処理）」が極めて曖昧であり、この記述ではテスト担当者は正常系・異常系のテストケース
を作成することが不可能である。

各プラグイン（少なくとも汎用プラグインであるTSV/CSV/固定長）について、独立した仕様
を記述する。 【ゴールデンケース（CSVプラグイン）】
1. **入力**: ファイルパス、エンコーディング、区切り文字、ヘッダー行の有無
2. **処理**:
   - 指定されたエンコーディングでファイルを開く。
   - ヘッダー行がある場合、1行目を読み飛ばす。
   - 1行ずつ読み込み、指定された区切り文字で分割する。
   - 分割後の各要素をInputスキーマの対応する列にマッピングする。
3. **出力**: onDataRowデリゲート経由でDataRowを返却。
4. **異常系**:
   - ファイルが見つからない場合のエラーコード。
   - 列数がスキーマと一致しない場合の処理（エラー、スキップなど）。

QA-2

QAManager: 用語と定義の明確化

△

2.1, 3, 4, 6.2

パラメータyaml、転記仕様yaml、スキーマyamlなど、多数の外部設定ファイルが処理の根幹をな
しているが、これらのファイルフォーマット（キー、データ型、必須/任意、構造）が定義されていな
い。例えば6.2でプラグインに渡されるJSON文字列のノード一覧はあるが、各ノード（例:
LineageReousceInfo）の内部構造が不明。これでは設定ファイルの作成やレビューが勘に頼る
ことになる。

巻末に付録として「設定ファイル仕様」を追加する。各YAML/JSONファイルについて、全て
のキーを階層構造で示し、それぞれの「キー名」「データ型」「必須/任意」「説明」「設定例」
をテーブル形式で網羅的に記述する。

QA-3

QAManager: 異常系の網羅性

△

4, 6.3.1, 8.1

起動パラメータのチェックやファイルが見つからない場合の考慮はされているが、実行中のI/O
エラー（ディスクフル、ネットワーク障害、権限不足など）に対する振る舞いが定義されていない。
例えば、「4. スキーマyamlファイルのダウンロード」でGCS接続に失敗した場合や、「8.1 DBログ
出力」でDB接続に失敗した場合のリカバリ処理（リトライなど）や終了コードが不明確。

QA-4

QAManager: 処理ロジックの具体性評価
(WDT分析)

×

6.3.2 データコンバート方法

データコンバート方法として`expr`と`expr_js`の2種類が挙げられているが、`expr`について「表
現式の実装は自分で実装する必要です」としか記述がなく、その実装・連携方法が全く不明。ど
のように外部実装を読み込み、実行するのかが定義されていないため、実装もテストも不可能
である。

主要なI/O処理（GCSダウンロード、DB書き込み、Parquetファイル出力）ごとに、異常系の
振る舞いを定義する。
【ゴールデンケース（DB書き込み失敗時）】
1. DBへの接続および書き込み処理で例外が発生した場合、5秒間隔で最大3回リトライす
る。
2. 3回のリトライ後も失敗した場合、処理を中断し、エラーログ（DB接続に失敗した旨、リト
ライ回数、最終的な例外情報）をコンソールおよびローカルファイルに出力する。
3. ツールは専用の終了コード（例: 251）で異常終了する。

`expr`の実現方式を具体的に定義する。
【ゴールデンケース（動的ロード方式）】
`expr`には「アセンブリ名,クラスのフルネーム,メソッド名」を文字列で指定する。ツールはリ
フレクションを用いて指定されたアセンブリをロードし、静的メソッドを呼び出す。そのメソッ
ドのシグネチャ（引数、戻り値の型）を `public static object Convert(object value, DataRow
currentRow)` のように厳密に定義する。アセンブリやメソッドが見つからない場合の例外
処理についても明記する。

対応有無
〇

×

×

×

×

×

対応方法／非対応理由

設計書内に要件定義書・
ルールブックへのハイパーリ
ンクを追加し、追跡性を確保
した。

リソース消費に関する内容は
既に「リソース消費」章で明
記済みであり、追加の章立て
は不要。

　本exeはプラグインを呼び
出す実行体であり、各プラグ
インの処理ロジックは個別仕
様書で管理されるため、本設
計書では対象外。

各設定ファイル
（YAML/JSON）の詳細仕様
は生成ツール側で定義・管
理されており、本設計書では
参照範囲に留める。

本設計書では正常系処理を
中心に記載しており、異常処
理は「例外処理」章に統合し
て記述済み。追加対応は不
要。

exprの実装・連携仕様は「プ
ログラム基本設計書_基礎-
コンポーネント
_ExpressionUtil」で詳細定義
済みのため、本書では概要
のみ記載。





================================================================================
ドキュメント: プログラム基本設計書_累積作成ツール_処理詳細_V8.pdf (PDF 2)
ファイル名: プログラム基本設計書_累積作成ツール_処理詳細_V8.pdf
================================================================================

3-1.処理詳細説明(全体)

プログラムID acumulate-file-loader

システム名 f013カタログ部品データ作成
業務機能名 累積作成
プログラム名称 累積EXE

システムID
バージョン
プロジェクトNo

12000599-00

作成日
更新日

2025/2/14
2025/11/6
区分

作成者
更新者

3H.尚坤
3H.尚坤

汎用

詳細内容

・起動パラメータ
コマンド:

acumulate-file-loader.exe -n workflow-namespace -w workflow-name -g lineage-group-id -s lineage-subgroup-id -t execute-task-id -p project-id -i input-path

パラメータ:

改訂No. 削

1/

短縮形式 長い形式

-n
-w
-g
-s
-t
-p
無し
-i
無し

必須/オプション
必須
--workflow-namespace
必須
--workflow-name
必須
--lineage-group-id
必須
--lineage-subgroup-id
オプション
--execute-task-id
必須
--project-id
オプション　※1・※2
--input-list-file
オプション　※2
--input-file
--input-file-selector             オプション　※2

機能
ネームスペース
ワークフロー名
リネージグループID
リネージサブグループID
タスクID
プロジェクトID
処理ユニットのセット(JSONファイル)
データソースファイルパス
処理対象ファイル選択

備考
Cloudログ出力用のnamespace
ワークフローの名前
データ処理のリネージID
このデータパイプラインの子ワークフローIDです
今回作業のタスクID
GCPで管理・操作するために、一意の識別子（ユニークID）
処理対象の複数のファイル情報が入っている json
データファイルはトリガーとする場合、非バッチ系、1つファイルの情報
プラグインが処理対象のデータ（ファイル）を特定するための選択子です。

※1 バッチ系の場合、処理対象は複数件ある場合、そのリストをJSON形のObject Listにして、

別途方法で、分割処理が必要です。

※2 運用上、この3つオプションのパラメータ（--input-list-file、-i/--input-file、--input-file-selector  ）は排他必要です。

・リソース消費

システムリソース負荷に影響する要因

項目
処理データ量
RowGroupSize
データ分布
特殊変換の複雑さ

説明
処理対象のテーブル数、各テーブルの行数・列数により処理量が増加
バッチ処理一度のデータ量（デフォルト1万）で、RowGroupSize が大きいほどメモリ使用量も増えます。
処理対象のファイルが分散配置されている場合、散在すればするほど検索時間が長くなります
特殊な変換処理が多ければ多いほど、処理時間が長くなり、メモリ消費量も増加します

あるサンプルデータでテスト結果 : 量化指標（実測値に基づくリソース消費の定量化）
データ処理量が増えるごとに、CPU使用率も高くなり、メモリ使用量も増加します。

RowGroupSize

特殊変換

10,000

ない

データ件数
500
5,000
1万
10万
100万
200万

CPU使用率
7%
17%
20%
21%
41%
45%

メモリ使用量(MB) ※1
30 MB
97 MB
134 MB
302 MB
1400 MB
2,505 MB

時間(s)
4 s
46 s
74 s
38 s
334 s
1,004 s

※1本処理で使用されるメモリ量は、Workflow の yaml に定義されたテンプレートのリソース制限（resources.limits.memory など）に依存します。

設定された上限を超えた場合、メモリオーバーフロー（OOM）が発生し、Pod が強制終了される可能性があります。

・処理詳細

1　ツール起動

上記「起動パラメータ」で定義した起動方法で起動して、下記の場合、異常で起動できないです。

＞　必須引数が未設定の場合、

コンソールに以下のエラーメッセージを表示し、ツール起動は失敗します。

Console ： 必須オプション「{optionName}」が未設定です。W/F動作時は定義YAMLテンプレートで引数に指定してください。
Console ： 累積作成ツール(acumulate-file-loader)
Console ： 使い方 : acumulate-file-loader.exe -n ネームスペース -w ワークフロー名 -p GCPプロジェクトID -g リネージグループID -s リネージサブグループID

Console ： Required option '{option}, {optionName}' is missing.

※ CommandLine API出力

＞　必須引数の値が空の場合、

コンソールに以下のエラーメッセージを表示し、ツール起動は失敗します。

Console ： 必須オプション 「{optionName}」 の値が空です。W/F動くの場合、定義Yamlの テンプレートの引数で値が指定されているか確認してください。

＞　三つのオプション引数(-i/--input-file 、 --input-list-file と --input-file-selector)は２つ以上設定された場合、

コンソールに以下のエラーメッセージを表示し、ツール起動は失敗します。

Console ： オプション 「-i/--input-file」, 「--input-list-file」, 「--input-file-selector」は同時に指定できません。どちらか一方のみを指定してください。

＞　上記の必須、オプション以外の引数が設定された場合、

コンソールに以下のエラーメッセージを表示し、ツール起動は失敗します。

Console ： 不明なオプション「{unknown}」が指定されました。入力パラメータを確認してください。

Console ： 累積作成ツール(acumulate-file-loader)

Console ： 使い方 : acumulate-file-loader.exe -n ネームスペース -w ワークフロー名 -p GCPプロジェクトID -g リネージグループID -s リネージサブグループID

Console ： Option '{unknown}' is unknown.

※ CommandLine API出力

2.　ツール初期処理

2.1　バラメータyamlファイルの内容の読込・チェック、リネージ情報の取得
リネージグループ、サブグループ、ワークフローなどを初期化します。

リネージグループID、リネージサブグループIDで、バラメータyamlファイル名を決めて、
・
・

「ワークフローID」　: 「リネージグループID + リネージサブグループID」
「parameter_(ワークフローID).yaml」

ツール実行に必要なリネージ設定情報、各種パラメータを、事前に作成されたパラメータyamlファイルから、リネージの対応情報をリードします。

Copyright(c) 2020 Broadleaf Co.,Ltd.

13
13
13

13
13
13

4
4
4
5
4
4
4
4

4
4
4
4
4
4
4

12

12

6
6

PTE-010-35.0303-01_プログラム基本設計書

・パラメータyamlファイル(parameter_(ワークフローID).yaml)の存在チェック

> パラメータyaml(parameter_(ワークフローID).yaml) が見つかった場合、処理用のリネージ情報を取得します。

ツール実行用のリネージ設定内容をバラメータyamlから取得しておいて

ツール実行に必要なリネージIDを取得します。(バラメータyamlに、ワークフローのリネージサブグループにあるリネージ設定は全て入ってる)
・すべてのLineage情報の取得および設定パラメータの取得

パラメータyamlファイルを読込み、「ParameterInfoEntity」にキャシューします。

> パラメータyaml(parameter_(ワークフローID).yaml) が見つからない場合、

エラーメッセージを表示して、処理中断します。

指定された引数「{lineage-group-id}」と「{lineage-subgroup-id}」で決まったバラメータyamlファイル「{parameterFilePath}」が見つかりません。

※ログ出力の設定すらないため、当該ログはコンソールに出力します。

2.2　ログ初期化

ログ出力の初期化

初期化バラメータ：
project-id
execute_task_id
process_id
workflow-name
name-space
logfilepath
logtypelist
loglevel

GCPリソースを管理・操作する際に使用する、一意の識別子（ユニークID）
実行タスクID
プロセス識別用の一意なID
現在のワークフローの名称
ログ出力用のnamespace
ログ出力ファイルのパス
ログ出力先設定リスト（console, local, cloudlogging）
ログレベル（release, debug）

「workflow_config_common.yml」ファイルに設定できて、LOG出力は下記の3つ設定可能です。

-console
-local
-cloud_logging

コンソールにログを出力します。
ローカルファイルにログを保存します。
CloudLogging 上にログを出力します。

2.3 リネージの処理開始ログ、「データリネージ実行ログ」に開始ログの出力

ツールが処理対象の設定情報(リネージ)を取得するために、リネージID（lineage_id）が必要です。
ツールプロセスID(processId)、引数のタスクID(task_id)を使います。

＞　リネージID（lineage_id）が1件のみ取得できた場合

処理開始ログの出力

処理の開始時に、確定できたリネージIDで、バラメータyamlファイルからリネージ名（process_name）を取得し、下記のInfoタイプログを出力する：

INFORMATION タイプ: 「{process_name}」 を開始します...

「データリネージ実行ログ」への開始ログ出力

本リネージ処理の開始情報を「データリネージ実行ログ」テーブルに出力します。
※環境変数からリソース管理DBの接続情報を取得します。

設定項目

設定内容

№

1

2

3

4

ログインデックスID
リネージグループID
リネージサブグループID
リネージID
適用バージョン

5
6 実行順序
プロセスID
7
8 ワークフローID
実行日
9
10 実行時間
11
12 実行スタータス
詳細メッセージ
13
14 入力ファイル
出力ファイル
15

実行フェーズ

log_index_id
lineage_group_id
lineage_sub_group_id
lineage_id
PGのバージョン番号
lineage_no
PGID
workflow_name
YYYYMMDD
HHMMSSFFFFFF
start:処理開始
info:情報
処理開始提示メッセージ
作業対象ファイルパス
空

＞　上記以外の場合

リネージ情報が特定できない場合、ログを出力し、「8　処理完了ログ出力およびDBログ出力」を実行し、終了する。
＞　リネージID（lineage_id） が1件も取得できなかった場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : パラメータYAML「{parameterYamlFile}」で、プロセスID「{processId}」・タスクID「{taskId}」に該当するリネージ定義は見つかりません。

＞　リネージID（lineage_id） が複数件取得された場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : パラメータYAML「{parameterYamlFile}」で、プロセスID「{processId}」・タスクID「{taskId}」のリネージ定義が重複しています。

上記いずれのケースでも、「データリネージ実行ログ」に異常開始ログを出力します。

※環境変数からリソース管理DBの接続情報を取得します。

№

設定項目

設定内容

3

1

2

ログインデックスID
リネージグループID
リネージサブグループID
リネージID
4
5 適用バージョン
6 実行順序
プロセスID
7
8 ワークフローID
9 実行日
10 実行時間

log_index_id
lineage_group_id
lineage_sub_group_id
空
空
空
PGID
workflow_name
YYYYMMDD
HHMMSSFFFFFF

2/

内容修正、ソース修正必要です。

内容修正、ソース修正必要です。

6
6
6
6
6
6
6
6
6
12

6
6

14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14

14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
15
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14

備考
AUTO_INCREMENT
-
-
-
-
-
-
-
-
-
処理開始ステータス
-
「{process_name}」 を開始します...
-
-

備考
AUTO_INCREMENT
-
-
リネージIDの取得に失敗したため、空とします
リネージID関連項目が取得できなかったため、空とします
リネージID関連項目が取得できなかったため、空とします
-
-
-
-

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

実行フェーズ

11
12 実行スタータス
13 詳細メッセージ
14 入力ファイル
出力ファイル
15

start:処理開始
error：エラー
エラー情報
作業対象ファイルパス
空

上記の処理、データベースに接続する必要があります。

データベース接続できない場合、

エラーログ：

ERRORタイプ：DB関連情報が正しく設定されていません。

2.4 リネージ情報関連のチェック

上記リネージIDが特定できて、リネージ情報の設定をチェックします。

2.4.1 当該リネージIDの入出力情報（リネージの入出力リソース情報）が存在しない場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : 「データリネージ連携テーブル」に当リネージID「{LineageID}」の入出力定義が見つかりません。

2.4.2 拡張機能情報1(extend_function_info_1)が未設定の場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : 「データリネージプロセス管理テーブル」に当リネージID「{LineageID}」の「拡張機能情報1(extend_function_info_1)」が未設定です。

2.4.3 拡張機能情報1が設定されているが、DLLファイルが存在しない場合、エラーログを以下の形式で出力します。

エラーログ

ERROR :  「データリネージプロセス管理テーブル」に当リネージID「{LineageID}」の拡張機能情報1(extend_function_info_1)で指定されたDLLファイル「{ExtendFunctionInfo1}」が見つかりません。

2.4.4 データ圧縮方式（compressMethodExpr）が設定されており、設定書式が不正な場合、エラーログを以下の形式で出力します。

エラーログ

ERROR :  「リソース管理テーブル」に当リネージID「{LineageID}」のデータ圧縮方式（compress_method）の書式が不正です。このようにする必要です：logical:<値>, local:<値>（例：logical:parquet_gzip, local:7z）。

2.4.5 データ論理圧縮方法が設定されており、設定にエラーがある場合、エラーログを以下の形式で出力します。

エラーログ

処理開始ステータス
-
リネージID取得できないの原因、上記リネージID特定できない原因を使う
-
-

14
14
15
14
14

3/

内容修正、ソース修正必要です。

内容修正、ソース修正必要です。

内容修正、ソース修正必要です。

内容修正、ソース修正必要です。

ERROR :  「リソース管理テーブル」に当リネージID「{LineageID}」のデータ論理圧縮方式「{compressMethod}」は、parquet_brotli、parquet_gzip、parquet_lz4、parquet_lzo、parquet_snappy、または parquet_zstd のいずれかである必要があります。

内容修正、ソース修正必要です。

2.4.6 データ物理圧縮方法が設定されており、設定にエラーがある場合、エラーログを以下の形式で出力します。

エラーログ

ERROR :  「リソース管理テーブル」に当リネージID「{LineageID}」のデータ物理圧縮方法「{fileCompressMethod}」は、7z または zip のいずれかである必要があります。

内容修正、ソース修正必要です。

3 リネージIDに基づいて転記仕様yamlファイルの確定と読み込み

 指定されたリネージIDに基づき、対応する転記仕様YAMLファイル（transform_spec.(リネージID).yaml）を特定し、パースします。
※　ワークフローで使用する転記仕様 yaml ファイルは、Argo Workflows の artifacts 機能により、事前に共有・参照可能な状態となっています。

プロセスログ

PROCESS タイプ： 転記仕様YAMLファイル「{transSpecYamlPath}」の読み込み 実行

転記仕様yamlファイル（transform_spec_(リネージID).yaml）の内容を読み取っておいて

・転記仕様yamlファイルが見つかりました、

転記仕様yaml「transform_spec_(リネージID).yaml」を見て、このリネージで指定した転記情報を取得します。

・ 転記仕様yamlファイルが見つからないと、処理中断します。

エラーログ

ERROR タイプ: 転記仕様YAMLファイル「{transSpecYamlPath}」が見つかりません。

4　入力、出力データファイルのレイアウト定義用スキーマyamlファイルのダウンロード

Input、Outputスキーマyamlファイルをダウンロードします。

パラメータyaml、転記仕様yamlから操作対象ファイルの定義情報を抽出し、指定GCSから、当該スキーマyamlファイルをダウンロードします。

プロセスログ

PROCESS タイプ： 入力・出力ファイルのスキーマ YAML ファイルのダウンロード 実行

まず、各スキーマyamlファイルの保存箇所を取得して、

バラメータyamlファイル(parameter_(ワークフローID).yaml)から、下記の情報を取得します：

・bucket: スキーマyamlファイルが保存されているGCSのバケット名。
ノード「setting_info」のサブノード「GCS」のサブノード「bucket」

・schemayamlpath: スキーマyamlファイルのパス。

ノード「setting_info」のサブノード「GCS」のサブノード「schemayamlpath」

 次に、対象のスキーマyamlファイル名を取得して

転記仕様yamlファイル(transform_spec_(リネージID).yaml)にから、下記の情報を取得します：

・Inputスキーマyamlファイル

ノード「input_file」の全てのサブノード「schemafilepath」

・Outputスキーマyamlファイル

ノード「output_file」の全てのサブノード「schemafilepath」

取得した bucket、schemayamlpath と Inputスキーマyamlファイル名、Outputスキーマyamlファイル名 を利用して、GCSから対象のスキーマyamlファイルをダウンロードします。
ダウンロードに失敗した場合、共通DLLがダウンロード失敗のログメッセージを出力します。

5　処理対象リスト作成

起動パラメータ（-i/--input-file 、 --input-list-file 、--input-file-selector ）で指定された処理対象に対して、

Copyright(c) 2020 Broadleaf Co.,Ltd.

DownloadSchemaFile
パラメータ：

・転記仕様yaml
・ワークフロー設定情報

機能：

lineage で使用される可能性のある schema yaml ファイルのダウンロード

内容修正、ソース修正必要です。

内容修正、ソース修正必要です。

7
7
14
14

14
14

5
5

5
5

PTE-010-35.0303-01_プログラム基本設計書

本リネージの設定に基づきグループ化を行い、処理を実行します。

> パラメータ (-i/--input-file) だけを設定した場合

入力ファイル名が命名規則に従っているかのチェック

＞ 入力ファイル名が命名規則に従っていない場合：

エラーログを出力する（ExitCode：244）

ERROR タイプ： 対象データファイル「{excelFilePath}」は、当リネージの命名規則「{fileNameRule}」に適合しません。

以下の処理を実行する：

・ 単一ファイルを対象リストに格納します。

> パラメータ (input-file-selector ) だけを設定した場合

以下の処理を実行する：

・ 処理対象を対象リストに格納します。

> パラメータ (--input-list-file) だけを設定した場合

以下の処理を実行する：

· JSON ファイルを読み込み、対象リストに格納します。

> -i/--input-file、--input-list-file、および --input-file-selector のいずれも設定されていない場合

以下の処理を実行する：

・ 「repository 」と「filenamerule」に基づき、対象ファイルリストに格納します。

プロセスログ

PROCESS タイプ： 処理対象リスト：{objList}

6　対象データファイルから、データをリードして、データコンバートを実行し、Parquetファイルを作成します。

データリード、データコンバート、Parquetファイルに書きこみの流れで実施します。

6.1 Inputスキーマ、Outスキーマyamlファイルのリード

コンバート処理開始時に、InputスキーマyamlファイルおよびOutputスキーマyamlファイルを解析し、必要な情報を取得します。

① Inputスキーマyamlファイルの解析

プロセスログ

PROCESS タイプ： 入力スキーマ YAML「{SchemaFilePath}」ファイルを解析し、標準転記の表現式　取得

・Before表現式の取得

special_transformノードに値が設定されている場合、そのカラムのBeforeに対応する辞書に表現式を格納します。

② Outputスキーマyamlファイルの解析

プロセスログ

PROCESS タイプ： 出力スキーマ YAML「{SchemaFilePath}」ファイルを解析し、標準転記の表現式　取得

・Main/After表現式の取得

special_transformノードに値が設定されている場合、そのカラムのMain/Afterに対応する辞書に表現式を格納します。

・RowGroupKeyの取得

RowGroupKeyノードに値が設定されている場合、その値を取得し記録します。

・RowGroupSizeの取得

RowGroupSizeノードに値が設定されている場合、その値を取得し記録します。
RowGroupSizeノードに値が設定されていない場合、デフォルトのバッチ処理は次の条件で実行されます：

①、データが500MBのメモリを占有した場合（優先判定）
②、上記に該当せず、行数が1万行に達した場合

6.2　コールバック駆動のデータ取込・正規化（to Inputスキーマ）

データを行単位で読み込み、検証・正規化後、Inputスキーマ準拠レコードをコールバックで逐次返却する方式を定義します。

 「データリネージプロセス管理テーブル」に基づき、リネージID「{LineageID}」の「拡張機能情報1（extend_function_info_1）」で指定されたプラグインを使用して、
データファイルを処理します。

プラグインの指定取得:

「parameter_（ワークフローID）.yaml」ファイルに、リネージ「リネージID」ノードの「ExtendFunctionInfo1」の設定値で判断します。

・プラグインが指定された場合、プラグインの対象データファイルを読み込みます。

下記のデータタイプに対しては、それぞれのデータ形式やレイアウトに応じたプラグインを設計し、
デリゲートコールバック方式でデータレコードを返すようにします。

・Excel
・PDF
・HTML
・Parquet
・TSV/CSV/固定長

←専用
←専用
←専用
←汎用、B145に実装します
←汎用、B145にテキストファイル解析プラグインとして実装します

※上記以外のデータタイプや解析形式を将来的に追加する場合は、プラグインを新規作成するだけで対応可能とします。

振分モジュール経由で、指定されたプラグインを起動します。

引数:

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

・onDataRow デリゲート
・logUtil LogUtil インスタンス  プラグインにもログ出力するために、追加して
・JSON形式の文字列

処理済みのDataRowを受け取るデリゲート

リネージ関連の各種情報

4/

内容修正、ソース修正必要です。

内容修正、ソース修正必要です。

LineageId明确指定了Plugin  DLL 名称：

4
4
3

3

6
6

6

14

6
6
6
6

14

6
6
6
6
6
6
6
6
8
8
8

12
12

5

6
12

14
14
14
14
14
14

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

詳細については、「プログラム基本設計書_プラグイン_振分モジュール_解析加工IF定義」を参照してください。

※JSON文字列には、以下の構造でデータ処理パイプラインの設定情報が含まれています。
ノード名
LineageGroupID
LineageSubGroupId
LineageId
LineageSummary
LineageReousceInfo
TransformyamlInfoDic
DataFileList
MacroVariable
WorkFlowSettings
EventFileContent

説明
リネージグループID
リネージサブグループID
リネージID
リネージ関連情報
リネージリソース情報
入力ファイル情報辞書
入力ファイルリスト
マクロ変数
ワークフロー設定情報
イベントファイル内容

詳細内容
データ処理のリネージグループID
このデータパイプラインの子ワークフローIDです
呼び出し元のリネージ定義 LineageId
リネージのプラグイン、プロセス名称などの設定情報
入出力リソースのエンコーディング、入出力区分、圧縮方式などの設定情報
入力ファイルのrepository、ファイル名称ルール、スキーマyaml名等設定情報
対象ファイルフルパスリスト
マクロ変数定義(マクロ変数名と正則表現)
ログ出力、GCSパス、作業・出力ディレクトリなど、ワークフロー実行に必要な設定
処理実行の契機となるイベント設定。ジョブ情報、通知先メールアドレス、通知API、などを含む。

・プラグインの設定がない場合、

設定不正として、エラーとして、累積ツールを異常終了（255）にします。
エラーログ：

ERROR  タイプ : 「データリネージプロセス管理」で、当リネージID「{0}」の「拡張機能情報1(extend_function_info_1)」が未設定です。

6.3　上記ロードできたデータレコードに対し、データコンバートをしてから、Parquetファイルに出力

メモリコストを控えるために、RowGroupSizeでメモリキャシューをしてから、データコンバート～Parquetファイル出力を行います。

6.3.1　Parquetファイル生成方式の分岐

OutputスキーマyamlファイルのRowGroupKey設定の有無によるParquetファイル生成方式の条件分け

・RowGroupKeyが設定されていない場合、直接Parquetファイルを生成
・RowGroupKeyが設定されている場合、DuckDBを経由してParquetファイルを生成

＞　RowGroupKeyを設定していない場合、直接Parquetファイルに出力

OutputスキーマyamlファイルのRowGroupSizeで、Parquetファイルに出力

1) データコンバート(入力レコード⇒出力レコードの変換)

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマカラム操作をして

「6.3.2　データコンバート方法」を参照してください。

エラーが発生した場合、以下の形式でメッセージを出力します。

ERROR/WARNING  タイプ :エラーファイル: {filepath}
ERROR/WARNING  タイプ :エラー行番号: {num}
ERROR/WARNING  タイプ :エラー明細: 列「{colname}」内容「{data}」は定義最大長さ「{Length}」を超えています。
ERROR/WARNING  タイプ :エラー明細: データ「{data}」を指定「{type}」に変換できません。
ERROR/WARNING  タイプ :エラー明細: データ列 「{colName}」は NULL を許可していないため、NULL 値は設定できません。

2) Parquetファイル出力

上記データリスト(RowGroupSize)で、コンバートできたデータをParquetファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

プロセスログ

PROCESS タイプ： 「{rowCount}」件のレコード コンバートできて、出力ファイルに「{rowCount}」件のレコード 追加

＞　RowGroupKeyを設定している場合、DuckDBにキャシューして、Parquetファイルに出力

DuckDBへのデータ追加のバッチ処理は、次の条件で実行されます：

①、 データが500MBのメモリを達した場合（優先判定）
②、 上記に該当せず、行数が10万行に達した場合

・データコンバート

1) データコンバート(入力レコード⇒出力レコードの変換)

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマ操作をして

「6.3.2　データコンバート方法」を参照してください。

データ変換・データチェック

① NULL 非許可の項目に NULL 値が設定された場合に出力します。

ERROR/WARNING タイプ : エラーファイル : {filepath}
ERROR/WARNING タイプ : エラー行番号 : {num}
ERROR/WARNING タイプ : エラー明細 : データ列「{colName}」は NULL を許可していないため、NULL 値を設定できません。

② 入力データを定義されたデータ型に変換できなかった場合に出力します。

ERROR/WARNING タイプ : エラーファイル : {filepath}
ERROR/WARNING タイプ : エラー行番号 : {num}
ERROR/WARNING タイプ : エラー明細 : データ「{data}」を指定された型「{type}」に変換できません。

③ 入力データの項目値が、定義された最大長を超過した場合に出力します。

ERROR/WARNING タイプ : エラーファイル : {filepath}
ERROR/WARNING タイプ : エラー行番号 : {num}
ERROR/WARNING タイプ : エラー明細 : 列「{colname}」の内容「{data}」は定義された最大長「{Length}」を超えています。

2) コンバートできたデータを DuckDB にインポート（ディスクベース）

対象の コンバートできたデータを DuckDB にインポートし、中間テーブルとして保存します。
メモリ上ではなく、ディスクベースで処理を行うことで、大容量データにも対応可能とします。

Copyright(c) 2020 Broadleaf Co.,Ltd.

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

14

6
6
6
6
6
6
6
6
6
6
6
6

5
9
9
12
14

5

7

7
7

7

7

7

7
7

14

7
8
8
8
7

7

7

7

5/

内容修正、ソース修正必要です。

PTE-010-35.0303-01_プログラム基本設計書

プロセスログ

PROCESS タイプ： 「{rowCount}」件のレコード コンバートできて、DuckDBに「{rowCount}」件のレコード 追加

· Parquetファイル出力

指定RowGroupKeyで、Parquetファイルを生成

Outputスキーマyamlファイルに「RowGroupKey」の指定がある場合だけ、指定キーでもう一回グループして、Parquetファイルの生成を行います。

※データコンバートできたら、更にRowGroupKeyでグループする必要です。

1)　RowGroupKey によるグループ化処理

DuckDB 上のテーブルに対し、RowGroupKeyでデータをグループ化します。
グループ単位で再構成されたデータセットを、SQL を用いて取得・加工します。
※メモリコストを考慮した上で、実装する必要です。

2)　Parquetファイルの生成

＞　RowGroupSizeを設定している場合

RowGroupKey により分割された各グループ内で、 RowGroupSize 件数単位に分割。
分割されたデータごとに、Parquet ファイルに追加モードで出力します。

＞　RowGroupSizeを設定していない場合

RowGroupKey により分割されたデータごとに、Parquet ファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

6.3.2　データコンバート方法

プラグインからonDataRow経由で受け取った各レコードを、指定された転記仕様YAMLに基づき、
リアルタイムでデータコンバートを実施します。

1)Inputスキーマyamlに、カラム表現式にBefore指定あり項目に対して、更にコンバートします。

元データに、ブリ処理をする必要か否かは、カラムの表現式にbefore計算式で記載してるので、

Inputスキーマyamlにカラム表現式に、「Before」変換式があるカラムに対し、指定表現式でコンバートを行う。

＞ Before表現式が設定ありカラム

カラム毎に、Beforeカラム表現式の操作をします。

※表現式の書き方は、下記2種類があります。 詳細は、「プログラム基本設計書_基礎-コンポーネント_ExpressionUtil」に参照

・expr

表現式の実装は自分で実装する必要です。

・expr_js

表現式の実行は、自分で実装する必要なし、規格に則った記述にすれば、JavaScript エンジンがその表現式を解釈し、実行してくれます。
Jint（ジント）は、.NET アプリケーション上で JavaScript を実行するための ECMAScript エンジン です。
C# など .NET 言語から JavaScript を呼び出して実行できる、軽量で高性能な JavaScript インタプリタです。

2) プリ処理できたレイアウトを出力レイアウトへのマッピングとデータ転送

コンバート処理が完了したデータは、出力レイアウトにマッピングしたら、データを転送する

Outputスキーマyamlファイルに設定された「ITEM_MATCH_MODE」に基づいて、入力解析結果のデータと出力レイアウトの間でカラムマッピング
※詳細は、ルールブックの「2. 入力ファイルと出力ファイルの列マッピングルール（ITEM_MATCH_MODE）」を参照。

3) Outputスキーマyamlに、カラム表現式にMain/After指定あり項目に対して、更にコンバートします。

Main/After変換辞書に記録されている各カラムおよび対応する表現式を使って、「Main→After」の順に変換を行う。

＞　Main/After表現式が設定されているカラム

・カラム毎に、Mainカラム表現式の操作をします。
・カラム毎に、Afterカラム表現式の操作をします。

6.3.3　Parquetファイル出力共通設定

Parquetファイルについて、出力方法と圧縮モードもバラメータyamlから取得して、

・出力処理方式（io_div）

GCSストリームにするか、ローカルに出力するかを判断します。
この io_divは、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード → 「io_div」ノードに設定しています。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「3-1　入出力区分（io_div）」を参照。

・論理圧縮（compress_method）

Parquetファイルの出力する際の論理圧縮方法を決定します。
論理圧縮の方法は、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード→ 「compress_method」ノードに指定してます。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「5-5　圧縮方式(compress_method)」を参照。

7　作成できたParquetファイルの物理圧縮

プロセスログ

PROCESS タイプ： 出力ファイルの物理圧縮 実行

物理圧縮指定有り場合、共通の圧縮方法を使って、Parquetファイルの圧縮を実施します。

共通「DwhFileProcessUtil」を利用して、出力ファイルを圧縮します。
file:物理圧縮方法

圧縮なしの場合は、noneを設定しますか、空を設定します

設定内容

Parquet作成後の物理圧縮方法

Copyright(c) 2020 Broadleaf Co.,Ltd.

14

7
7
7
7

7
7
7
7
7
7
7
7
7
7
7
7
7

14
14

7
6
6
6
6
6
6
6
6
6
6
6
6
6

7
5
5
5
5
5
5
7
6
6
6
6
6

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7

14
14

6/

内容修正、ソース修正必要です。

所有的Batch都完

PTE-010-35.0303-01_プログラム基本設計書

空白 または file:none
file:zip
file:7z
...

圧縮しない
zip
7z
...

※物理圧縮の場合、パスワード指定有りの場合、暗号化かけて、圧縮します。

INFORMATIONログ

INFORMATION タイプ：出力ファイル：{outputFilePath}
INFORMATION タイプ：出力レコード件数: {recordCount}

8　処理完了ログ出力およびDBログ出力

8.1　「データリネージ実行ログ」テーブルに、今回実行の結果をログに出力する。
処理完了の基本情報を「データリネージ実行ログ」テーブルに出力します。
※環境変数からリソース管理DBの接続情報を取得

ログインデックスID
リネージグループID
リネージサブグループID
リネージID
適用バージョン

№ 設定項目
1
2
3
4
5
6 実行順序
プロセスID
7
8 ワークフローID
実行日
9
10 実行時間
11

実行フェーズ

設定内容
log_index_id
lineage_group_id
lineage_sub_group_id
lineage_id
PGのバージョン番号
lineage_no
PGID
workflow_name
YYYYMMDD
HHMMSSFFFFFF
end:処理終了

12 実行スタータス

ok:正常終了,warning:警告,error:エラー

13

詳細メッセージ

処理結果情報、エラー情報等

14 入力ファイル
15
出力ファイル

作業対象ファイルパス
Parquetファイルパス

8.2　ログ出力

処理終了ログの出力

処理の終了時に、リネージ名（process_name）を使用して、以下の形式でログを出力する：

> 正常完了

INFORMATION タイプ: 「{process_name}」が正常完了しました。

> 異常終了

WARNING タイプ: 「{process_name}」が異常終了しました。(警告：{exitcode})
ERROR タイプ: 「{process_name}」が異常終了しました。(エラー：{exitcode})
ERROR タイプ： {ex.StackTrace}

転記仕様yamlの「loginfo」の設定により、転記仕様yamlの「logtype」で指定された方法（コンソールログ、ローカルファイル、クロードロギング）を利用してログを出力します

ログタイトル：

2024/02/01 16:53:11 [情報] (NameSpace: ネームスペース WorkFlowName: ワークフロー名 ExecuteTaskId:実行タスクID)

ログ内容：

・基本な設定情報

リネージグループID、リネージID、PGID、execute_task_idなど

・ファイル情報

入出力ファイルパス、途中作成ファイル（パラメータyaml、転記仕様yaml）など情報

・設定情報のチェック結果
設定不正な情報

・開始、終了情報

各処理ステープの開始、終了情報、exit codeなど

logの例：

2024/02/01 16:53:11 [情報  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 実行時単位ID(リネージグループID-リネージID) :L00005
2024/02/01 16:53:11 [情報  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツールID :acumulate-file-loader
2024/02/01 16:53:11 [情報  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックが開始しました...
2024/02/01 16:53:11 [情報  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様スキーマ：D:\tmp\transform_spec.yml
2024/02/01 16:53:11 [情報  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツール実行前チェックを行います...
2024/02/01 16:53:11 [情報  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)
2024/02/01 16:53:11 [情報  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックが正常完了しました。
2024/02/01 16:53:11 [エラー ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様にoutfileのfilenameruleの設定が不正ため、下記のinfileに対しますoutfileの名称が重複になります。
2024/02/01 16:53:11 [エラー ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0001.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [エラー ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0002.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [警告  ] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 累積処理が異常終了しました。(警告：99)

Copyright(c) 2020 Broadleaf Co.,Ltd.

7/

14
14
14

11

備考
AUTO_INCREMENT
-
-
-
-
-
-
-
-
-
-

複数種類のエラーが検知された場合、
エラーハンドリング設定に従い、ExitCodeが最後のエラー情報を出力する。

※最後のエラー情報とは、以下の2種類のうち、最後に出力された Msg を指します。
  ① 振り分けモジュールで呼び出された Plugin の After 処理の戻り値（Msg）
  ② exe 実行中に発生したエラー情報

※512文字まで残って、それ以上、切り捨て

-
-

PTE-010-35.0303-01_プログラム基本設計書

8/

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書





================================================================================
ドキュメント: プログラム基本設計書_累積作成ツール_処理詳細_V7.pdf (今回の設計書 V7)
ファイル名: プログラム基本設計書_累積作成ツール_処理詳細_V7.pdf
================================================================================

3-1.処理詳細説明(全体)

プログラムID acumulate-file-loader

システム名 f013カタログ部品データ作成
業務機能名 累積作成
プログラム名称 累積EXE

システムID
バージョン
プロジェクトNo

12000599-00

作成日
更新日

2025/2/14
2025/10/30
区分

作成者
更新者

3H.尚坤
3H.尚坤

汎用

詳細内容

・起動パラメータ
コマンド:

acumulate-file-loader.exe -n workflow-namespace -w workflow-name -g lineage-group-id -s lineage-subgroup-id -t execute-task-id -p project-id -i input-path

1/

改訂No. 削

備考
Cloudログ出力用のnamespace
ワークフローの名前
データ処理のリネージID
このデータパイプラインの子ワークフローIDです
今回作業のタスクID
GCPで管理・操作するために、一意の識別子（ユニークID）
処理対象の複数のファイル情報が入っている json
データファイルはトリガーとする場合、非バッチ系、1つファイルの情報
プラグインが処理対象のデータ（ファイル）を特定するための選択子です。

パラメータ:

短縮形式 長い形式

-n
-w
-g
-s
-t
-p
無し
-i
無し

--workflow-namespace
--workflow-name
--lineage-group-id
--lineage-subgroup-id
--execute-task-id
--project-id
--input-list-file
--input-file
--input-file-selector

必須/オプション
必須
必須
必須
必須
オプション
必須
オプション　※1・※2
オプション　※2
オプション　※2

機能
ネームスペース
ワークフロー名
リネージグループID
リネージサブグループID
タスクID
プロジェクトID
処理ユニットのセット(JSONファイル)
データソースファイルパス
処理対象ファイル選択

※1 バッチ系の場合、処理対象は複数件ある場合、そのリストをJSON形のObject Listにして、

別途方法で、分割処理が必要です。

※2 運用上、この3つオプションのパラメータ（--input-list-file、-i/--input-file、--input-file-selector  ）は排他必要です。

・リソース消費

システムリソース負荷に影響する要因

項目
処理データ量
RowGroupSize
データ分布
特殊変換の複雑さ

説明
処理対象のテーブル数、各テーブルの行数・列数により処理量が増加
バッチ処理一度のデータ量（デフォルト1万）で、RowGroupSize が大きいほどメモリ使用量も増えます。
処理対象のファイルが分散配置されている場合、散在すればするほど検索時間が長くなります
特殊な変換処理が多ければ多いほど、処理時間が長くなり、メモリ消費量も増加します

あるサンプルデータでテスト結果 : 量化指標（実測値に基づくリソース消費の定量化）
データ処理量が増えるごとに、CPU使用率も高くなり、メモリ使用量も増加します。

RowGroupSize

特殊変換

10,000

ない

データ件数
500
5,000
1万
10万
100万
200万

CPU使用率
7%
17%
20%
21%
41%
45%

メモリ使用量(MB) ※1
30 MB
97 MB
134 MB
302 MB
1400 MB
2,505 MB

時間(s)
4 s
46 s
74 s
38 s
334 s
1,004 s

※1本処理で使用されるメモリ量は、Workflow の yaml に定義されたテンプレートのリソース制限（resources.limits.memory など）に依存します。

設定された上限を超えた場合、メモリオーバーフロー（OOM）が発生し、Pod が強制終了される可能性があります。

・処理詳細

1　ツール起動

上記「起動パラメータ」仕様を参照して起動します。

＞　必要の引数が未設定の場合、

コンソールエラーメッセージ「必須オプション「xxxx」が未設定です。W/F動作時は定義YAMLテンプレートで引数に指定してください。」を表示して、ツール起動に失敗

> 排他の引数(-i/--input-file と --input-list-file と --input-file-selector)が同時設定の場合、

コンソールエラーメッセージ「オプション 「-i/--input-file」, 「--input-list-file」, 「--input-file-selector」は同時に指定できません。どちらか一方のみを指定してください。」を表示して、ツール起動に失敗

13
13
13

13
13
13

4
4
4
5
4
4
4
4

4
4
4
4
4
4
4

12

12

2.　ツール初期処理

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

2.1　バラメータyaml設定内容の読込・チェック、リネージ情報の取得

リネージグループ、サブグループ、ワークフローなどを初期化します。

リネージグループID、リネージサブグループIDで、バラメータyamlファイル名を決めて、
・
・

「ワークフローID」　: 「リネージグループID + リネージサブグループID」
「parameter_(ワークフローID).yaml」

ツール実行に必要なリネージ設定情報、各種パラメータを、事前に作成されたパラメータyamlファイルから、リネージの対応情報をリードします。

・パラメータyamlファイル(parameter_(ワークフローID).yaml)の存在チェック

> パラメータyaml(parameter_(ワークフローID).yaml) が見つかった場合、処理用のリネージ情報を取得します。

ツール実行用のリネージ設定内容をバラメータyamlから取得しておいて

ツール実行に必要なリネージIDを取得します。(バラメータyamlに、ワークフローのリネージサブグループにあるリネージ設定は全て入ってる)
・すべてのLineage情報の取得および設定パラメータの取得

パラメータyamlファイルを読込み、「ParameterInfoEntity」にキャシューします。

> パラメータyaml(parameter_(ワークフローID).yaml) が見つからない場合、

エラーメッセージ「指定されたパラメータファイル「xxxx」が見つかりません。」を表示して、処理中断します。
※ログ出力の設定すらもないなので、コンソール画面にこのログを出力します。

2.2　ログ初期化

ログ出力の初期化

初期化バラメータ：
project-id
execute_task_id
process_id
workflow-name
name-space
logfilepath
logtypelist
loglevel

GCPリソースを管理・操作する際に使用する、一意の識別子（ユニークID）
実行タスクID
プロセス識別用の一意なID
現在のワークフローの名称
ログ出力用のnamespace
ログ出力ファイルのパス
ログ出力先設定リスト（console, local, cloudlogging）
ログレベル（release, debug）

「workflow_config_common.yml」ファイルに設定できて、LOG出力は下記の3つ設定可能です。

-console
-local
-cloud_logging

コンソールにログを出力します。
ローカルファイルにログを保存します。
CloudLogging 上にログを出力します。

2.3 リネージの処理開始ログ、「データリネージ実行ログ」に開始ログの出力

ツールが処理対象の設定情報(リネージ)を取得するために、リネージID（lineage_id）が必要です。
ツールプロセスID(processId)、引数のタスクID(task_id)を使います。

＞　リネージID（lineage_id）が1件のみ取得できた場合

処理開始ログの出力

処理の開始時に、リネージ名（process_name）を使用して、以下の形式でログを出力する：

INFO : 「{process_name}」 を開始します...

「データリネージ実行ログ」への開始ログ出力

本リネージ処理の開始情報を「データリネージ実行ログ」テーブルに出力します。

※環境変数からリソース管理DBの接続情報を取得します。

設定項目

設定内容

№

1

2

3

4

ログインデックスID
リネージグループID
リネージサブグループID
リネージID

Copyright(c) 2020 Broadleaf Co.,Ltd.

log_index_id
lineage_group_id
lineage_sub_group_id
lineage_id

備考
AUTO_INCREMENT
-
-
-

2/

6
6
6
6
6
6
6
6
6
6
6
12
6
6

14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14

PTE-010-35.0303-01_プログラム基本設計書

適用バージョン

5
6 実行順序
プロセスID
7
8 ワークフローID
実行日
9
10 実行時間
11
12 実行スタータス
詳細メッセージ
13
14 入力ファイル
出力ファイル
15

実行フェーズ

PGのバージョン番号
lineage_no
PGID
workflow_name
YYYYMMDD
HHMMSSFFFFFF
start:処理開始
info:情報
処理開始提示メッセージ
作業対象ファイルパス
空

-
-
-
-
-
-
処理開始ステータス
-
-
-
-

＞　上記以外の場合

＞　リネージID（lineage_id） が1件も取得できなかった場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : パラメータYAML「{parameterYamlFile}」で、プロセスID「{processId}」・タスクID「{taskId}」に該当するリネージ定義は見つかりません。

＞　リネージID（lineage_id） が複数件取得された場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : パラメータYAML「{parameterYamlFile}」で、プロセスID「{processId}」とタスクID「{taskId}」のリネージ定義が重複しています。

上記いずれのケースでも、「データリネージ実行ログ」に異常開始ログを出力します。

※環境変数からリソース管理DBの接続情報を取得します。

№

設定項目

設定内容

3

2

1

ログインデックスID
リネージグループID
リネージサブグループID
リネージID
4
5 適用バージョン
6 実行順序
プロセスID
7
8 ワークフローID
9 実行日
10 実行時間
11
12 実行スタータス
13 詳細メッセージ
14 入力ファイル
出力ファイル
15

実行フェーズ

log_index_id
lineage_group_id
lineage_sub_group_id
空
空
空
PGID
workflow_name
YYYYMMDD
HHMMSSFFFFFF
start:処理開始
error：エラー
空
作業対象ファイルパス
空

備考
AUTO_INCREMENT
-
-
リネージIDの取得に失敗したため、空とします
リネージID関連項目が取得できなかったため、空とします
リネージID関連項目が取得できなかったため、空とします
-
-
-
-
処理開始ステータス
-
-
-
-

3/

14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14

3 リネージIDに基づいて転記仕様yamlファイルの確定と読み込み

 指定されたリネージIDに基づき、対応する転記仕様YAMLファイル（transform_spec.(リネージID).yaml）を特定し、パースします。
※　ワークフローで使用する転記仕様 yaml ファイルは、Argo Workflows の artifacts 機能により、事前に共有・参照可能な状態となっています。

プロセスログ

PROCESS タイプ： 転記仕様のYAMLファイル「{transSpecYamlPath}」の読み込み 実行

転記仕様yamlファイル（transform_spec_(リネージID).yaml）の内容を読み取っておいて

・転記仕様yamlファイルが見つかりました、

転記仕様yaml「transform_spec_(リネージID).yaml」を見て、このリネージで指定した転記情報を取得します。

・ 転記仕様yamlファイルが見つからないと、処理中断します。

エラーログ

Copyright(c) 2020 Broadleaf Co.,Ltd.

ERROR タイプ: 転記仕様ファイル「{transSpecYamlPath}」が見つかりません。

7
7
14
14

PTE-010-35.0303-01_プログラム基本設計書

4　入力、出力データファイルのレイアウト定義用スキーマyamlファイルのダウンロード

Input、Outputスキーマyamlファイルをダウンロードします。

パラメータyaml、転記仕様yamlから操作対象ファイルの定義情報を抽出し、指定GCSから、当該スキーマyamlファイルをダウンロードします。

プロセスログ

PROCESS タイプ： 入力・出力ファイルのスキーマ YAML ファイルのダウンロード 実行

まず、各スキーマyamlファイルの保存箇所を取得して、

バラメータyamlファイル(parameter_(ワークフローID).yaml)から、下記の情報を取得します：

・bucket: スキーマyamlファイルが保存されているGCSのバケット名。
ノード「setting_info」のサブノード「GCS」のサブノード「bucket」

・schemayamlpath: スキーマyamlファイルのパス。

ノード「setting_info」のサブノード「GCS」のサブノード「schemayamlpath」

 次に、対象のスキーマyamlファイル名を取得して

転記仕様yamlファイル(transform_spec_(リネージID).yaml)にから、下記の情報を取得します：

・Inputスキーマyamlファイル

ノード「input_file」の全てのサブノード「schemafilepath」

・Outputスキーマyamlファイル

ノード「output_file」の全てのサブノード「schemafilepath」

DownloadSchemaFile
パラメータ：

・転記仕様yaml
・ワークフロー設定情報

機能：

lineage で使用される可能性のある schema yaml ファイルのダウンロード

取得した bucket、schemayamlpath と Inputスキーマyamlファイル名、Outputスキーマyamlファイル名 を利用して、GCSから対象のスキーマyamlファイルをダウンロードします。

5　処理対象リスト作成

起動パラメータ（-i/--input-file 、 --input-list-file 、--input-file-selector ）で指定された処理対象に対して、
本リネージの設定に基づきグループ化を行い、処理を実行します。

> パラメータ (-i/--input-file) だけを設定した場合

入力ファイル名が命名規則に従っているかのチェック

＞ 入力ファイル名が命名規則に従っていない場合：

エラーログを出力する（ExitCode：244）

ERROR タイプ： 対象データファイル「{excelFilePath}」は、当リネージの命名規則「{fileNameRule}」に適合しません。

以下の処理を実行する：

・ 単一ファイルを対象リストに格納します。

> パラメータ (input-file-selector ) だけを設定した場合

以下の処理を実行する：

・ 処理対象を対象リストに格納します。

> パラメータ (--input-list-file) だけを設定した場合

以下の処理を実行する：

· JSON ファイルを読み込み、対象リストに格納します。

> -i/--input-file、--input-list-file、および --input-file-selector のいずれも設定されていない場合

以下の処理を実行する：

・ 「repository 」と「filenamerule」に基づき、対象ファイルリストに格納します。

6　対象データファイルから、データをリードして、データコンバートを実行し、Parquetファイルを作成します。

データリード、データコンバート、Parquetファイルに書きこみの流れで実施します。

Copyright(c) 2020 Broadleaf Co.,Ltd.

6.1 Inputスキーマ、Outスキーマyamlファイルのリード

4/

14
14

5
5

5
5

4
4
3
3

PTE-010-35.0303-01_プログラム基本設計書

6

コンバート処理開始時に、InputスキーマyamlファイルおよびOutputスキーマyamlファイルを解析し、必要な情報を取得します。

① Inputスキーマyamlファイルの解析

プロセスログ

PROCESS タイプ： 入力スキーマ YAML「{SchemaFilePath}」ファイルを解析し、標準転記の表現式を取得します...

・Before表現式の取得

special_transformノードに値が設定されている場合、そのカラムのBeforeに対応する辞書に表現式を格納します。

② Outputスキーマyamlファイルの解析

プロセスログ

PROCESS タイプ： 出力スキーマ YAML「{SchemaFilePath}」ファイルを解析し、標準転記の表現式を取得します...

・Main/After表現式の取得

special_transformノードに値が設定されている場合、そのカラムのMain/Afterに対応する辞書に表現式を格納します。

・RowGroupKeyの取得

RowGroupKeyノードに値が設定されている場合、その値を取得し記録します。

・RowGroupSizeの取得

RowGroupSizeノードに値が設定されている場合、その値を取得し記録します。
RowGroupSizeノードに値が設定されていない場合、デフォルトのバッチ処理は次の条件で実行されます：

①、データが500MBのメモリを占有した場合（優先判定）
②、上記に該当せず、行数が1万行に達した場合

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

6.2　コールバック駆動のデータ取込・正規化（to Inputスキーマ）

データを行単位で読み込み、検証・正規化後、Inputスキーマ準拠レコードをコールバックで逐次返却する方式を定義します。

プロセスログ

PROCESS タイプ： 対象データファイル「{input_data_file}」の読み込み 実行

リネージの処理対処データソースファイルにより、使うプラグインを選んで処理します。
プラグインの指定があるかどうかを判定し、それに応じてデータファイルのロード処理を行います。

プラグインの指定取得:

「parameter_（ワークフローID）.yaml」ファイルに、リネージ「リネージID」ノードの「ExtendFunctionInfo1」の設定値で判断します。

・プラグインが指定された場合、プラグインの対象データファイルを読み込みます。

下記のデータタイプに対しては、それぞれのデータ形式やレイアウトに応じたプラグインを設計し、
デリゲートコールバック方式でデータレコードを返すようにします。

・Excel
・PDF
・HTML
・Parquet
・TSV/CSV/固定長

←専用
←専用
←専用
←汎用、B145に実装します
←汎用、B145にテキストファイル解析プラグインとして実装します

※上記以外のデータタイプや解析形式を将来的に追加する場合は、プラグインを新規作成するだけで対応可能とします。

振分モジュール経由で、指定されたプラグインを起動します。

引数:

・onDataRow デリゲート
・logUtil LogUtil インスタンス  プラグインにもログ出力するために、追加して
・JSON形式の文字列

処理済みのDataRowを受け取るデリゲート

リネージ関連の各種情報

Copyright(c) 2020 Broadleaf Co.,Ltd.

5/

6

6

14
14

6
6
6
6

14
14

6
6
6
6
6
6
6
6
8
8
8

12
12

14
14

5

6
12

14
14
14
14
14

PTE-010-35.0303-01_プログラム基本設計書

詳細については、「プログラム基本設計書_プラグイン_振分モジュール_解析加工IF定義」を参照してください。

6/

14
14

※JSON文字列には、以下の構造でデータ処理パイプラインの設定情報が含まれています。
ノード名
LineageGroupID
LineageSubGroupId
LineageId
LineageSummary
LineageReousceInfo
TransformyamlInfoDic
DataFileList
MacroVariable
WorkFlowSettings
EventFileContent

説明
リネージグループID
リネージサブグループID
リネージID
リネージ関連情報
リネージリソース情報
入力ファイル情報辞書
入力ファイルリスト
マクロ変数
ワークフロー設定情報
イベントファイル内容

詳細内容
データ処理のリネージグループID
このデータパイプラインの子ワークフローIDです
呼び出し元のリネージ定義 LineageId
リネージのプラグイン、プロセス名称などの設定情報
入出力リソースのエンコーディング、入出力区分、圧縮方式などの設定情報
入力ファイルのrepository、ファイル名称ルール、スキーマyaml名等設定情報
対象ファイルフルパスリスト
マクロ変数定義(マクロ変数名と正則表現)
ログ出力、GCSパス、作業・出力ディレクトリなど、ワークフロー実行に必要な設定
処理実行の契機となるイベント設定。ジョブ情報、通知先メールアドレス、通知API、などを含む。

・プラグインの設定がない場合、

設定不正として、エラーとして、累積ツールを異常終了（255）にします。
エラーログ：

ERROR  タイプ : 「データリネージプロセス管理」で、当リネージID「{0}」の「拡張機能情報1(extend_function_info_1)」が未設定です。

6.3　上記ロードできたデータレコードに対し、データコンバートをしてから、Parquetファイルに出力

メモリコストを控えるために、RowGroupSizeでメモリキャシューをしてから、データコンバート～Parquetファイル出力を行います。

6.3.1　Parquetファイル生成方式の分岐

OutputスキーマyamlファイルのRowGroupKey設定の有無によるParquetファイル生成方式の条件分け

・RowGroupKeyが設定されていない場合、直接Parquetファイルを生成
・RowGroupKeyが設定されている場合、DuckDBを経由してParquetファイルを生成

＞　RowGroupKeyを設定していない場合、直接Parquetファイルに出力

OutputスキーマyamlファイルのRowGroupSizeで、Parquetファイルに出力

1) データコンバート(入力レコード⇒出力レコードの変換)

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマカラム操作をして

「6.3.2　データコンバート方法」を参照してください。

2) Parquetファイル出力

上記データリスト(RowGroupSize)で、コンバートできたデータをParquetファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

プロセスログ

PROCESS タイプ： データレコードのコンバート完了、出力ファイルに「{table.Count}」件のレコードを追加。

＞　RowGroupKeyを設定している場合、DuckDBにキャシューして、Parquetファイルに出力

DuckDBへのデータ追加のバッチ処理は、次の条件で実行されます：

①、 データが500MBのメモリを達した場合（優先判定）
②、 上記に該当せず、行数が10万行に達した場合

・データコンバート

1) データコンバート(入力レコード⇒出力レコードの変換)

Copyright(c) 2020 Broadleaf Co.,Ltd.

「6.3.2　データコンバート方法」を参照してください。

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマ操作をして

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

6
6
6
6
6
6
6
6
6
6
6
6

5
9
9
12
14

5

7

7
7

7
7
7

7
7

14
14

7
8
8
8
7

7

7

PTE-010-35.0303-01_プログラム基本設計書

2) コンバートできたデータを DuckDB にインポート（ディスクベース）

対象の コンバートできたデータを DuckDB にインポートし、中間テーブルとして保存します。
メモリ上ではなく、ディスクベースで処理を行うことで、大容量データにも対応可能とします。

プロセスログ

PROCESS タイプ： データレコードのコンバート完了、DuckDBに「{rowCount}」件のレコードを追加。

· Parquetファイル出力

指定RowGroupKeyで、Parquetファイルを生成

Outputスキーマyamlファイルに「RowGroupKey」の指定がある場合だけ、指定キーでもう一回グループして、Parquetファイルの生成を行います。

※データコンバートできたら、更にRowGroupKeyでグループする必要です。

1)　RowGroupKey によるグループ化処理

DuckDB 上のテーブルに対し、RowGroupKeyでデータをグループ化します。
グループ単位で再構成されたデータセットを、SQL を用いて取得・加工します。
※メモリコストを考慮した上で、実装する必要です。

2)　Parquetファイルの生成

＞　RowGroupSizeを設定している場合

RowGroupKey により分割された各グループ内で、 RowGroupSize 件数単位に分割。
分割されたデータごとに、Parquet ファイルに追加モードで出力します。

＞　RowGroupSizeを設定していない場合

RowGroupKey により分割されたデータごとに、Parquet ファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

6.3.1　データコンバート方法

プラグインからonDataRow経由で受け取った各レコードを、指定された転記仕様YAMLに基づき、
リアルタイムでデータコンバートを実施します。

1)Inputスキーマyamlに、カラム表現式にBefore指定あり項目に対して、更にコンバートします。

元データに、ブリ処理をする必要か否かは、カラムの表現式にbefore計算式で記載してるので、

Inputスキーマyamlにカラム表現式に、「Before」変換式があるカラムに対し、指定表現式でコンバートを行う。

＞ Before表現式が設定ありカラム

カラム毎に、Beforeカラム表現式の操作をします。

※表現式の書き方は、下記2種類があります。 詳細は、「プログラム基本設計書_基礎-コンポーネント_ExpressionUtil」に参照

・expr

表現式の実装は自分で実装する必要です。

・expr_js

表現式の実行は、自分で実装する必要なし、規格に則った記述にすれば、JavaScript エンジンがその表現式を解釈し、実行してくれます。
Jint（ジント）は、.NET アプリケーション上で JavaScript を実行するための ECMAScript エンジン です。
C# など .NET 言語から JavaScript を呼び出して実行できる、軽量で高性能な JavaScript インタプリタです。

7/

7
7

14
14

7
7
7
7

7
7
7
7
7
7
7
7
7
7
7
7
7

7

14
14

7
6
6
6
6
6
6
6
6
6
6
6
6
6

2) プリ処理できたレイアウトを出力レイアウトへのマッピングとデータ転送

コンバート処理が完了したデータは、出力レイアウトにマッピングしたら、データを転送する

Outputスキーマyamlファイルに設定された「ITEM_MATCH_MODE」に基づいて、入力解析結果のデータと出力レイアウトの間でカラムマッピング
※詳細は、ルールブックの「2. 入力ファイルと出力ファイルの列マッピングルール（ITEM_MATCH_MODE）」を参照。

Copyright(c) 2020 Broadleaf Co.,Ltd.

7
5
5
5
5
5

PTE-010-35.0303-01_プログラム基本設計書

8/

5
7
6
6
6
6
6

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7

14
14

3) Outputスキーマyamlに、カラム表現式にMain/After指定あり項目に対して、更にコンバートします。

Main/After変換辞書に記録されている各カラムおよび対応する表現式を使って、「Main→After」の順に変換を行う。

＞　Main/After表現式が設定されているカラム

・カラム毎に、Mainカラム表現式の操作をします。
・カラム毎に、Afterカラム表現式の操作をします。

6.3.3　Parquetファイル出力共通設定

Parquetファイルについて、出力方法と圧縮モードもバラメータyamlから取得して、

・出力処理方式（io_div）

GCSストリームにするか、ローカルに出力するかを判断します。
この io_divは、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード → 「io_div」ノードに設定しています。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「3-1　入出力区分（io_div）」を参照。

・論理圧縮（compress_method）

Parquetファイルの出力する際の論理圧縮方法を決定します。
論理圧縮の方法は、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード→ 「compress_method」ノードに指定してます。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「5-5　圧縮方式(compress_method)」を参照。

7　作成できたParquetファイルの物理圧縮

プロセスログ

PROCESS タイプ： 出力ファイル「{outputFilePath}」の物理圧縮 実行

物理圧縮指定有り場合、共通の圧縮方法を使って、Parquetファイルの圧縮を実施します。

共通「DwhFileProcessUtil」を利用して、出力ファイルを圧縮します。
file:物理圧縮方法

圧縮なしの場合は、noneを設定しますか、空を設定します

設定内容
空白 または file:none
file:zip
file:7z
...

Parquet作成後の物理圧縮方法
圧縮しない
zip
7z
...

※物理圧縮の場合、パスワード指定有りの場合、暗号化かけて、圧縮します。

8　処理完了ログ出力およびDBログ出力

8.1　「データリネージ実行ログ」テーブルに、今回実行の結果をログに出力する。
処理完了の基本情報を「データリネージ実行ログ」テーブルに出力します。
※環境変数からリソース管理DBの接続情報を取得

№ 設定項目
1
2
3
4
5
6 実行順序
プロセスID
7
Copyright(c) 2020 Broadleaf Co.,Ltd.

ログインデックスID
リネージグループID
リネージサブグループID
リネージID
適用バージョン

設定内容
log_index_id
lineage_group_id
lineage_sub_group_id
lineage_id
PGのバージョン番号
lineage_no
PGID

備考
AUTO_INCREMENT
-
-
-
-
-
-

PTE-010-35.0303-01_プログラム基本設計書

8 ワークフローID
9
実行日
10 実行時間
11

実行フェーズ

workflow_name
YYYYMMDD
HHMMSSFFFFFF
end:処理終了

12 実行スタータス

ok:正常終了,warning:警告,error:エラー

-
-
-
-

9/

13

詳細メッセージ

処理結果情報、エラー情報等

14 入力ファイル
15
出力ファイル

作業対象ファイルパス
Parquetファイルパス

複数種類のエラーが検知された場合、
エラーハンドリング設定に従い、ExitCodeが最後のエラー情報を出力する。

※最後のエラー情報とは、以下の2種類のうち、最後に出力された Msg を指します。
  ① 振り分けモジュールで呼び出された Plugin の After 処理の戻り値（Msg）
  ② exe 実行中に発生したエラー情報

11

※512文字まで残って、それ以上、切り捨て

-
-

8.2　ログ出力

転記仕様yamlの「loginfo」の設定により、転記仕様yamlの「logtype」で指定された方法（コンソールログ、ローカルファイル、クロードロギング）を利用してログを出力します

ログタイトル：

2024/02/01 16:53:11 [情報] (NameSpace: ネームスペース WorkFlowName: ワークフロー名 ExecuteTaskId:実行タスクID)

ログ内容：

・基本な設定情報

リネージグループID、リネージID、PGID、execute_task_idなど

・ファイル情報

入出力ファイルパス、途中作成ファイル（パラメータyaml、転記仕様yaml）など情報

・設定情報のチェック結果
設定不正な情報

・開始、終了情報

各処理ステープの開始、終了情報、exit codeなど

logの例：

2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 実行時単位ID(リネージグループID-リネージID) :L00005
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツールID :acumulate-file-loader
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックが開始しました...
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様スキーマ：D:\tmp\transform_spec.yml
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツール実行前チェックを行います...
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックが正常完了しました。
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様にoutfileのfilenameruleの設定が不正ため、下記のinfileに対しますoutfileの名称が重複になります。
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0001.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0002.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [警告] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 累積処理が異常終了しました。(警告：99)

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

10/

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書



