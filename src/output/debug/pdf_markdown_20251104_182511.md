# プログラム基本設計書_累積作成ツール (5)_処理詳細_V7

3-1.処理詳細説明(全体)

プログラムID acumulate-file-loader

システム名 f013カタログ部品データ作成
業務機能名 累積作成
プログラム名称 累積EXE

システムID
バージョン
プロジェクトNo

12000599-00

作成日
更新日

2025/2/14
2025/10/30
区分

作成者
更新者

3H.尚坤
3H.尚坤

汎用

詳細内容

・起動パラメータ
コマンド:

acumulate-file-loader.exe -n workflow-namespace -w workflow-name -g lineage-group-id -s lineage-subgroup-id -t execute-task-id -p project-id -i input-path

1/

改訂No. 削

備考
Cloudログ出力用のnamespace
ワークフローの名前
データ処理のリネージID
このデータパイプラインの子ワークフローIDです
今回作業のタスクID
GCPで管理・操作するために、一意の識別子（ユニークID）
処理対象の複数のファイル情報が入っている json
データファイルはトリガーとする場合、非バッチ系、1つファイルの情報
プラグインが処理対象のデータ（ファイル）を特定するための選択子です。

パラメータ:

短縮形式 長い形式

-n
-w
-g
-s
-t
-p
無し
-i
無し

--workflow-namespace
--workflow-name
--lineage-group-id
--lineage-subgroup-id
--execute-task-id
--project-id
--input-list-file
--input-file
--input-file-selector

必須/オプション
必須
必須
必須
必須
オプション
必須
オプション　※1・※2
オプション　※2
オプション　※2

機能
ネームスペース
ワークフロー名
リネージグループID
リネージサブグループID
タスクID
プロジェクトID
処理ユニットのセット(JSONファイル)
データソースファイルパス
処理対象ファイル選択

※1 バッチ系の場合、処理対象は複数件ある場合、そのリストをJSON形のObject Listにして、

別途方法で、分割処理が必要です。

※2 運用上、この3つオプションのパラメータ（--input-list-file、-i/--input-file、--input-file-selector  ）は排他必要です。

・リソース消費

システムリソース負荷に影響する要因

項目
処理データ量
RowGroupSize
データ分布
特殊変換の複雑さ

説明
処理対象のテーブル数、各テーブルの行数・列数により処理量が増加
バッチ処理一度のデータ量（デフォルト1万）で、RowGroupSize が大きいほどメモリ使用量も増えます。
処理対象のファイルが分散配置されている場合、散在すればするほど検索時間が長くなります
特殊な変換処理が多ければ多いほど、処理時間が長くなり、メモリ消費量も増加します

あるサンプルデータでテスト結果 : 量化指標（実測値に基づくリソース消費の定量化）
データ処理量が増えるごとに、CPU使用率も高くなり、メモリ使用量も増加します。

RowGroupSize

特殊変換

10,000

ない

データ件数
500
5,000
1万
10万
100万
200万

CPU使用率
7%
17%
20%
21%
41%
45%

メモリ使用量(MB) ※1
30 MB
97 MB
134 MB
302 MB
1400 MB
2,505 MB

時間(s)
4 s
46 s
74 s
38 s
334 s
1,004 s

※1本処理で使用されるメモリ量は、Workflow の yaml に定義されたテンプレートのリソース制限（resources.limits.memory など）に依存します。

設定された上限を超えた場合、メモリオーバーフロー（OOM）が発生し、Pod が強制終了される可能性があります。

・処理詳細

1　ツール起動

上記「起動パラメータ」仕様を参照して起動します。

＞　必要の引数が未設定の場合、

コンソールエラーメッセージ「必須オプション「xxxx」が未設定です。W/F動作時は定義YAMLテンプレートで引数に指定してください。」を表示して、ツール起動に失敗

> 排他の引数(-i/--input-file と --input-list-file と --input-file-selector)が同時設定の場合、

コンソールエラーメッセージ「オプション 「-i/--input-file」, 「--input-list-file」, 「--input-file-selector」は同時に指定できません。どちらか一方のみを指定してください。」を表示して、ツール起動に失敗

13
13
13

13
13
13

4
4
4
5
4
4
4
4

4
4
4
4
4
4
4

12

12

2.　ツール初期処理

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

2.1　バラメータyaml設定内容の読込・チェック、リネージ情報の取得

リネージグループ、サブグループ、ワークフローなどを初期化します。

リネージグループID、リネージサブグループIDで、バラメータyamlファイル名を決めて、
・
・

「ワークフローID」　: 「リネージグループID + リネージサブグループID」
「parameter_(ワークフローID).yaml」

ツール実行に必要なリネージ設定情報、各種パラメータを、事前に作成されたパラメータyamlファイルから、リネージの対応情報をリードします。

・パラメータyamlファイル(parameter_(ワークフローID).yaml)の存在チェック

> パラメータyaml(parameter_(ワークフローID).yaml) が見つかった場合、処理用のリネージ情報を取得します。

ツール実行用のリネージ設定内容をバラメータyamlから取得しておいて

ツール実行に必要なリネージIDを取得します。(バラメータyamlに、ワークフローのリネージサブグループにあるリネージ設定は全て入ってる)
・すべてのLineage情報の取得および設定パラメータの取得

パラメータyamlファイルを読込み、「ParameterInfoEntity」にキャシューします。

> パラメータyaml(parameter_(ワークフローID).yaml) が見つからない場合、

エラーメッセージ「指定されたパラメータファイル「xxxx」が見つかりません。」を表示して、処理中断します。
※ログ出力の設定すらもないなので、コンソール画面にこのログを出力します。

2.2　ログ初期化

ログ出力の初期化

初期化バラメータ：
project-id
execute_task_id
process_id
workflow-name
name-space
logfilepath
logtypelist
loglevel

GCPリソースを管理・操作する際に使用する、一意の識別子（ユニークID）
実行タスクID
プロセス識別用の一意なID
現在のワークフローの名称
ログ出力用のnamespace
ログ出力ファイルのパス
ログ出力先設定リスト（console, local, cloudlogging）
ログレベル（release, debug）

「workflow_config_common.yml」ファイルに設定できて、LOG出力は下記の3つ設定可能です。

-console
-local
-cloud_logging

コンソールにログを出力します。
ローカルファイルにログを保存します。
CloudLogging 上にログを出力します。

2.3 リネージの処理開始ログ、「データリネージ実行ログ」に開始ログの出力

ツールが処理対象の設定情報(リネージ)を取得するために、リネージID（lineage_id）が必要です。
ツールプロセスID(processId)、引数のタスクID(task_id)を使います。

＞　リネージID（lineage_id）が1件のみ取得できた場合

処理開始ログの出力

処理の開始時に、リネージ名（process_name）を使用して、以下の形式でログを出力する：

INFO : 「{process_name}」 を開始します...

「データリネージ実行ログ」への開始ログ出力

本リネージ処理の開始情報を「データリネージ実行ログ」テーブルに出力します。

※環境変数からリソース管理DBの接続情報を取得します。

設定項目

設定内容

№

1

2

3

4

ログインデックスID
リネージグループID
リネージサブグループID
リネージID

Copyright(c) 2020 Broadleaf Co.,Ltd.

log_index_id
lineage_group_id
lineage_sub_group_id
lineage_id

備考
AUTO_INCREMENT
-
-
-

2/

6
6
6
6
6
6
6
6
6
6
6
12
6
6

14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14

PTE-010-35.0303-01_プログラム基本設計書

適用バージョン

5
6 実行順序
プロセスID
7
8 ワークフローID
実行日
9
10 実行時間
11
12 実行スタータス
詳細メッセージ
13
14 入力ファイル
出力ファイル
15

実行フェーズ

PGのバージョン番号
lineage_no
PGID
workflow_name
YYYYMMDD
HHMMSSFFFFFF
start:処理開始
info:情報
処理開始提示メッセージ
作業対象ファイルパス
空

-
-
-
-
-
-
処理開始ステータス
-
-
-
-

＞　上記以外の場合

＞　リネージID（lineage_id） が1件も取得できなかった場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : パラメータYAML「{parameterYamlFile}」で、プロセスID「{processId}」・タスクID「{taskId}」に該当するリネージ定義は見つかりません。

＞　リネージID（lineage_id） が複数件取得された場合、エラーログを以下の形式で出力します。

エラーログ

ERROR : パラメータYAML「{parameterYamlFile}」で、プロセスID「{processId}」とタスクID「{taskId}」のリネージ定義が重複しています。

上記いずれのケースでも、「データリネージ実行ログ」に異常開始ログを出力します。

※環境変数からリソース管理DBの接続情報を取得します。

№

設定項目

設定内容

1

3

2

ログインデックスID
リネージグループID
リネージサブグループID
リネージID
4
5 適用バージョン
6 実行順序
プロセスID
7
8 ワークフローID
9 実行日
10 実行時間
11
12 実行スタータス
13 詳細メッセージ
14 入力ファイル
出力ファイル
15

実行フェーズ

log_index_id
lineage_group_id
lineage_sub_group_id
空
空
空
PGID
workflow_name
YYYYMMDD
HHMMSSFFFFFF
start:処理開始
error：エラー
空
作業対象ファイルパス
空

備考
AUTO_INCREMENT
-
-
リネージIDの取得に失敗したため、空とします
リネージID関連項目が取得できなかったため、空とします
リネージID関連項目が取得できなかったため、空とします
-
-
-
-
処理開始ステータス
-
-
-
-

3/

14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14

3 リネージIDに基づいて転記仕様yamlファイルの確定と読み込み

 指定されたリネージIDに基づき、対応する転記仕様YAMLファイル（transform_spec.(リネージID).yaml）を特定し、パースします。
※　ワークフローで使用する転記仕様 yaml ファイルは、Argo Workflows の artifacts 機能により、事前に共有・参照可能な状態となっています。

プロセスログ

PROCESS タイプ： 転記仕様のYAMLファイル「{transSpecYamlPath}」の読み込み 実行

転記仕様yamlファイル（transform_spec_(リネージID).yaml）の内容を読み取っておいて

・転記仕様yamlファイルが見つかりました、

転記仕様yaml「transform_spec_(リネージID).yaml」を見て、このリネージで指定した転記情報を取得します。

・ 転記仕様yamlファイルが見つからないと、処理中断します。

エラーログ

Copyright(c) 2020 Broadleaf Co.,Ltd.

ERROR タイプ: 転記仕様ファイル「{transSpecYamlPath}」が見つかりません。

7
7
14
14

PTE-010-35.0303-01_プログラム基本設計書

4　入力、出力データファイルのレイアウト定義用スキーマyamlファイルのダウンロード

Input、Outputスキーマyamlファイルをダウンロードします。

パラメータyaml、転記仕様yamlから操作対象ファイルの定義情報を抽出し、指定GCSから、当該スキーマyamlファイルをダウンロードします。

プロセスログ

PROCESS タイプ： 入力・出力ファイルのスキーマ YAML ファイルのダウンロード 実行

まず、各スキーマyamlファイルの保存箇所を取得して、

バラメータyamlファイル(parameter_(ワークフローID).yaml)から、下記の情報を取得します：

・bucket: スキーマyamlファイルが保存されているGCSのバケット名。
ノード「setting_info」のサブノード「GCS」のサブノード「bucket」

・schemayamlpath: スキーマyamlファイルのパス。

ノード「setting_info」のサブノード「GCS」のサブノード「schemayamlpath」

 次に、対象のスキーマyamlファイル名を取得して

転記仕様yamlファイル(transform_spec_(リネージID).yaml)にから、下記の情報を取得します：

・Inputスキーマyamlファイル

ノード「input_file」の全てのサブノード「schemafilepath」

・Outputスキーマyamlファイル

ノード「output_file」の全てのサブノード「schemafilepath」

DownloadSchemaFile
パラメータ：

・転記仕様yaml
・ワークフロー設定情報

機能：

lineage で使用される可能性のある schema yaml ファイルのダウンロード

取得した bucket、schemayamlpath と Inputスキーマyamlファイル名、Outputスキーマyamlファイル名 を利用して、GCSから対象のスキーマyamlファイルをダウンロードします。

5　処理対象リスト作成

起動パラメータ（-i/--input-file 、 --input-list-file 、--input-file-selector ）で指定された処理対象に対して、
本リネージの設定に基づきグループ化を行い、処理を実行します。

> パラメータ (-i/--input-file) だけを設定した場合

入力ファイル名が命名規則に従っているかのチェック

＞ 入力ファイル名が命名規則に従っていない場合：

エラーログを出力する（ExitCode：244）

ERROR タイプ： 対象データファイル「{excelFilePath}」は、当リネージの命名規則「{fileNameRule}」に適合しません。

以下の処理を実行する：

・ 単一ファイルを対象リストに格納します。

> パラメータ (input-file-selector ) だけを設定した場合

以下の処理を実行する：

・ 処理対象を対象リストに格納します。

> パラメータ (--input-list-file) だけを設定した場合

以下の処理を実行する：

· JSON ファイルを読み込み、対象リストに格納します。

> -i/--input-file、--input-list-file、および --input-file-selector のいずれも設定されていない場合

以下の処理を実行する：

・ 「repository 」と「filenamerule」に基づき、対象ファイルリストに格納します。

6　対象データファイルから、データをリードして、データコンバートを実行し、Parquetファイルを作成します。

データリード、データコンバート、Parquetファイルに書きこみの流れで実施します。

Copyright(c) 2020 Broadleaf Co.,Ltd.

6.1 Inputスキーマ、Outスキーマyamlファイルのリード

4/

14
14

5
5

5
5

4
4
3
3

PTE-010-35.0303-01_プログラム基本設計書

6

コンバート処理開始時に、InputスキーマyamlファイルおよびOutputスキーマyamlファイルを解析し、必要な情報を取得します。

① Inputスキーマyamlファイルの解析

プロセスログ

PROCESS タイプ： 入力スキーマ YAML「{SchemaFilePath}」ファイルを解析し、標準転記の表現式を取得します...

・Before表現式の取得

special_transformノードに値が設定されている場合、そのカラムのBeforeに対応する辞書に表現式を格納します。

② Outputスキーマyamlファイルの解析

プロセスログ

PROCESS タイプ： 出力スキーマ YAML「{SchemaFilePath}」ファイルを解析し、標準転記の表現式を取得します...

・Main/After表現式の取得

special_transformノードに値が設定されている場合、そのカラムのMain/Afterに対応する辞書に表現式を格納します。

・RowGroupKeyの取得

RowGroupKeyノードに値が設定されている場合、その値を取得し記録します。

・RowGroupSizeの取得

RowGroupSizeノードに値が設定されている場合、その値を取得し記録します。
RowGroupSizeノードに値が設定されていない場合、デフォルトのバッチ処理は次の条件で実行されます：

①、データが500MBのメモリを占有した場合（優先判定）
②、上記に該当せず、行数が1万行に達した場合

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

6.2　コールバック駆動のデータ取込・正規化（to Inputスキーマ）

データを行単位で読み込み、検証・正規化後、Inputスキーマ準拠レコードをコールバックで逐次返却する方式を定義します。

プロセスログ

PROCESS タイプ： 対象データファイル「{input_data_file}」の読み込み 実行

リネージの処理対処データソースファイルにより、使うプラグインを選んで処理します。
プラグインの指定があるかどうかを判定し、それに応じてデータファイルのロード処理を行います。

プラグインの指定取得:

「parameter_（ワークフローID）.yaml」ファイルに、リネージ「リネージID」ノードの「ExtendFunctionInfo1」の設定値で判断します。

・プラグインが指定された場合、プラグインの対象データファイルを読み込みます。

下記のデータタイプに対しては、それぞれのデータ形式やレイアウトに応じたプラグインを設計し、
デリゲートコールバック方式でデータレコードを返すようにします。

・Excel
・PDF
・HTML
・Parquet
・TSV/CSV/固定長

←専用
←専用
←専用
←汎用、B145に実装します
←汎用、B145にテキストファイル解析プラグインとして実装します

※上記以外のデータタイプや解析形式を将来的に追加する場合は、プラグインを新規作成するだけで対応可能とします。

振分モジュール経由で、指定されたプラグインを起動します。

引数:

・onDataRow デリゲート
・logUtil LogUtil インスタンス  プラグインにもログ出力するために、追加して
・JSON形式の文字列

処理済みのDataRowを受け取るデリゲート

リネージ関連の各種情報

Copyright(c) 2020 Broadleaf Co.,Ltd.

5/

6

6

14
14

6
6
6
6

14
14

6
6
6
6
6
6
6
6
8
8
8

12
12

14
14

5

6
12

14
14
14
14
14

PTE-010-35.0303-01_プログラム基本設計書

詳細については、「プログラム基本設計書_プラグイン_振分モジュール_解析加工IF定義」を参照してください。

6/

14
14

※JSON文字列には、以下の構造でデータ処理パイプラインの設定情報が含まれています。
ノード名
LineageGroupID
LineageSubGroupId
LineageId
LineageSummary
LineageReousceInfo
TransformyamlInfoDic
DataFileList
MacroVariable
WorkFlowSettings
EventFileContent

説明
リネージグループID
リネージサブグループID
リネージID
リネージ関連情報
リネージリソース情報
入力ファイル情報辞書
入力ファイルリスト
マクロ変数
ワークフロー設定情報
イベントファイル内容

詳細内容
データ処理のリネージグループID
このデータパイプラインの子ワークフローIDです
呼び出し元のリネージ定義 LineageId
リネージのプラグイン、プロセス名称などの設定情報
入出力リソースのエンコーディング、入出力区分、圧縮方式などの設定情報
入力ファイルのrepository、ファイル名称ルール、スキーマyaml名等設定情報
対象ファイルフルパスリスト
マクロ変数定義(マクロ変数名と正則表現)
ログ出力、GCSパス、作業・出力ディレクトリなど、ワークフロー実行に必要な設定
処理実行の契機となるイベント設定。ジョブ情報、通知先メールアドレス、通知API、などを含む。

・プラグインの設定がない場合、

設定不正として、エラーとして、累積ツールを異常終了（255）にします。
エラーログ：

ERROR  タイプ : 「データリネージプロセス管理」で、当リネージID「{0}」の「拡張機能情報1(extend_function_info_1)」が未設定です。

6.3　上記ロードできたデータレコードに対し、データコンバートをしてから、Parquetファイルに出力

メモリコストを控えるために、RowGroupSizeでメモリキャシューをしてから、データコンバート～Parquetファイル出力を行います。

6.3.1　Parquetファイル生成方式の分岐

OutputスキーマyamlファイルのRowGroupKey設定の有無によるParquetファイル生成方式の条件分け

・RowGroupKeyが設定されていない場合、直接Parquetファイルを生成
・RowGroupKeyが設定されている場合、DuckDBを経由してParquetファイルを生成

＞　RowGroupKeyを設定していない場合、直接Parquetファイルに出力

OutputスキーマyamlファイルのRowGroupSizeで、Parquetファイルに出力

1) データコンバート(入力レコード⇒出力レコードの変換)

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマカラム操作をして

「6.3.2　データコンバート方法」を参照してください。

2) Parquetファイル出力

上記データリスト(RowGroupSize)で、コンバートできたデータをParquetファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

プロセスログ

PROCESS タイプ： データレコードのコンバート完了、出力ファイルに「{table.Count}」件のレコードを追加。

＞　RowGroupKeyを設定している場合、DuckDBにキャシューして、Parquetファイルに出力

DuckDBへのデータ追加のバッチ処理は、次の条件で実行されます：

①、 データが500MBのメモリを達した場合（優先判定）
②、 上記に該当せず、行数が10万行に達した場合

・データコンバート

1) データコンバート(入力レコード⇒出力レコードの変換)

Copyright(c) 2020 Broadleaf Co.,Ltd.

「6.3.2　データコンバート方法」を参照してください。

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマ操作をして

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

6
6
6
6
6
6
6
6
6
6
6
6

5
9
9
12
14

5

7

7
7

7
7
7

7
7

14
14

7
8
8
8
7

7

7

PTE-010-35.0303-01_プログラム基本設計書

2) コンバートできたデータを DuckDB にインポート（ディスクベース）

対象の コンバートできたデータを DuckDB にインポートし、中間テーブルとして保存します。
メモリ上ではなく、ディスクベースで処理を行うことで、大容量データにも対応可能とします。

プロセスログ

PROCESS タイプ： データレコードのコンバート完了、DuckDBに「{rowCount}」件のレコードを追加。

· Parquetファイル出力

指定RowGroupKeyで、Parquetファイルを生成

Outputスキーマyamlファイルに「RowGroupKey」の指定がある場合だけ、指定キーでもう一回グループして、Parquetファイルの生成を行います。

※データコンバートできたら、更にRowGroupKeyでグループする必要です。

1)　RowGroupKey によるグループ化処理

DuckDB 上のテーブルに対し、RowGroupKeyでデータをグループ化します。
グループ単位で再構成されたデータセットを、SQL を用いて取得・加工します。
※メモリコストを考慮した上で、実装する必要です。

2)　Parquetファイルの生成

＞　RowGroupSizeを設定している場合

RowGroupKey により分割された各グループ内で、 RowGroupSize 件数単位に分割。
分割されたデータごとに、Parquet ファイルに追加モードで出力します。

＞　RowGroupSizeを設定していない場合

RowGroupKey により分割されたデータごとに、Parquet ファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

6.3.1　データコンバート方法

プラグインからonDataRow経由で受け取った各レコードを、指定された転記仕様YAMLに基づき、
リアルタイムでデータコンバートを実施します。

1)Inputスキーマyamlに、カラム表現式にBefore指定あり項目に対して、更にコンバートします。

元データに、ブリ処理をする必要か否かは、カラムの表現式にbefore計算式で記載してるので、

Inputスキーマyamlにカラム表現式に、「Before」変換式があるカラムに対し、指定表現式でコンバートを行う。

＞ Before表現式が設定ありカラム

カラム毎に、Beforeカラム表現式の操作をします。

※表現式の書き方は、下記2種類があります。 詳細は、「プログラム基本設計書_基礎-コンポーネント_ExpressionUtil」に参照

・expr

表現式の実装は自分で実装する必要です。

・expr_js

表現式の実行は、自分で実装する必要なし、規格に則った記述にすれば、JavaScript エンジンがその表現式を解釈し、実行してくれます。
Jint（ジント）は、.NET アプリケーション上で JavaScript を実行するための ECMAScript エンジン です。
C# など .NET 言語から JavaScript を呼び出して実行できる、軽量で高性能な JavaScript インタプリタです。

7/

7
7

14
14

7
7
7
7

7
7
7
7
7
7
7
7
7
7
7
7
7

7

14
14

7
6
6
6
6
6
6
6
6
6
6
6
6
6

2) プリ処理できたレイアウトを出力レイアウトへのマッピングとデータ転送

コンバート処理が完了したデータは、出力レイアウトにマッピングしたら、データを転送する

Outputスキーマyamlファイルに設定された「ITEM_MATCH_MODE」に基づいて、入力解析結果のデータと出力レイアウトの間でカラムマッピング
※詳細は、ルールブックの「2. 入力ファイルと出力ファイルの列マッピングルール（ITEM_MATCH_MODE）」を参照。

Copyright(c) 2020 Broadleaf Co.,Ltd.

7
5
5
5
5
5

PTE-010-35.0303-01_プログラム基本設計書

8/

5
7
6
6
6
6
6

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7

14
14

3) Outputスキーマyamlに、カラム表現式にMain/After指定あり項目に対して、更にコンバートします。

Main/After変換辞書に記録されている各カラムおよび対応する表現式を使って、「Main→After」の順に変換を行う。

＞　Main/After表現式が設定されているカラム

・カラム毎に、Mainカラム表現式の操作をします。
・カラム毎に、Afterカラム表現式の操作をします。

6.3.3　Parquetファイル出力共通設定

Parquetファイルについて、出力方法と圧縮モードもバラメータyamlから取得して、

・出力処理方式（io_div）

GCSストリームにするか、ローカルに出力するかを判断します。
この io_divは、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード → 「io_div」ノードに設定しています。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「3-1　入出力区分（io_div）」を参照。

・論理圧縮（compress_method）

Parquetファイルの出力する際の論理圧縮方法を決定します。
論理圧縮の方法は、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード→ 「compress_method」ノードに指定してます。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「5-5　圧縮方式(compress_method)」を参照。

7　作成できたParquetファイルの物理圧縮

プロセスログ

PROCESS タイプ： 出力ファイル「{outputFilePath}」の物理圧縮 実行

物理圧縮指定有り場合、共通の圧縮方法を使って、Parquetファイルの圧縮を実施します。

共通「DwhFileProcessUtil」を利用して、出力ファイルを圧縮します。
file:物理圧縮方法

圧縮なしの場合は、noneを設定しますか、空を設定します

設定内容
空白 または file:none
file:zip
file:7z
...

Parquet作成後の物理圧縮方法
圧縮しない
zip
7z
...

※物理圧縮の場合、パスワード指定有りの場合、暗号化かけて、圧縮します。

8　処理完了ログ出力およびDBログ出力

8.1　「データリネージ実行ログ」テーブルに、今回実行の結果をログに出力する。
処理完了の基本情報を「データリネージ実行ログ」テーブルに出力します。
※環境変数からリソース管理DBの接続情報を取得

№ 設定項目
1
2
3
4
5
6 実行順序
プロセスID
7
Copyright(c) 2020 Broadleaf Co.,Ltd.

ログインデックスID
リネージグループID
リネージサブグループID
リネージID
適用バージョン

設定内容
log_index_id
lineage_group_id
lineage_sub_group_id
lineage_id
PGのバージョン番号
lineage_no
PGID

備考
AUTO_INCREMENT
-
-
-
-
-
-

PTE-010-35.0303-01_プログラム基本設計書

8 ワークフローID
9
実行日
10 実行時間
11

実行フェーズ

workflow_name
YYYYMMDD
HHMMSSFFFFFF
end:処理終了

12 実行スタータス

ok:正常終了,warning:警告,error:エラー

-
-
-
-

9/

13

詳細メッセージ

処理結果情報、エラー情報等

14 入力ファイル
15
出力ファイル

作業対象ファイルパス
Parquetファイルパス

複数種類のエラーが検知された場合、
エラーハンドリング設定に従い、ExitCodeが最後のエラー情報を出力する。

※最後のエラー情報とは、以下の2種類のうち、最後に出力された Msg を指します。
  ① 振り分けモジュールで呼び出された Plugin の After 処理の戻り値（Msg）
  ② exe 実行中に発生したエラー情報

11

※512文字まで残って、それ以上、切り捨て

-
-

8.2　ログ出力

転記仕様yamlの「loginfo」の設定により、転記仕様yamlの「logtype」で指定された方法（コンソールログ、ローカルファイル、クロードロギング）を利用してログを出力します

ログタイトル：

2024/02/01 16:53:11 [情報] (NameSpace: ネームスペース WorkFlowName: ワークフロー名 ExecuteTaskId:実行タスクID)

ログ内容：

・基本な設定情報

リネージグループID、リネージID、PGID、execute_task_idなど

・ファイル情報

入出力ファイルパス、途中作成ファイル（パラメータyaml、転記仕様yaml）など情報

・設定情報のチェック結果
設定不正な情報

・開始、終了情報

各処理ステープの開始、終了情報、exit codeなど

logの例：

2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 実行時単位ID(リネージグループID-リネージID) :L00005
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツールID :acumulate-file-loader
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックが開始しました...
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様スキーマ：D:\tmp\transform_spec.yml
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツール実行前チェックを行います...
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックが正常完了しました。
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様にoutfileのfilenameruleの設定が不正ため、下記のinfileに対しますoutfileの名称が重複になります。
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0001.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0002.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [警告] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 累積処理が異常終了しました。(警告：99)

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

10/

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書



---

# プログラム基本設計書_累積作成ツール (5)_処理詳細_V6

3-1.処理詳細説明(全体)

プログラムID acumulate-file-loader

システム名 f013カタログ部品データ作成
業務機能名 累積作成
プログラム名称 累積EXE

システムID
バージョン
プロジェクトNo

12000599-00

作成日
更新日

2025/2/14
2025/10/24
区分

作成者
更新者

3H.尚坤
3H.尚坤

汎用

詳細内容

・起動パラメータ
コマンド:

acumulate-file-loader.exe -n workflow-namespace -w workflow-name -g lineage-group-id -s lineage-subgroup-id -t task-id -p project-id -i input-path

備考
Cloudログ出力用のnamespace
ワークフローの名前
データ処理のリネージID
このデータパイプラインの子ワークフローIDです
今回作業のタスクID
GCPで管理・操作するために、一意の識別子（ユニークID）
処理対象の複数のファイル情報が入っている json
データファイルはトリガーとする場合、非バッチ系、1つファイルの情報
プラグインが処理対象のデータ（ファイル）を特定するための選択子です。

パラメータ:

短縮形式 長い形式
-n
-w
-g
-s
-t
-p
無し
-i
無し

--workflow-namespace
--workflow-name
--lineage-group-id
--lineage-subgroup-id
--task-id
--project-id
--input-list-file
--input-file
--input-file-selector

必須/オプション
必須
必須
必須
必須
オプション
必須
オプション　※1・※2
オプション　※2
オプション　※2

機能
ネームスペース
ワークフロー名
リネージグループID
リネージサブグループID
タスクID
プロジェクトID
処理ユニットのセット(JSONファイル)
データソースファイルパス
処理対象ファイル選択

※1 バッチ系の場合、処理対象は複数件ある場合、そのリストをJSON形のObject Listにして、

別途方法で、分割処理が必要です。

※2 運用上、この3つオプションのパラメータ（--input-list-file、-i/--input-file、--input-file-selector  ）は排他必要です。

・リソース消費

システムリソース負荷に影響する要因

項目
処理データ量
RowGroupSize
データ分布
特殊変換の複雑さ

説明
処理対象のテーブル数、各テーブルの行数・列数により処理量が増加
バッチ処理一度のデータ量（デフォルト1万）で、RowGroupSize が大きいほどメモリ使用量も増えます。
処理対象のファイルが分散配置されている場合、散在すればするほど検索時間が長くなります
特殊な変換処理が多ければ多いほど、処理時間が長くなり、メモリ消費量も増加します

あるサンプルデータでテスト結果 : 量化指標（実測値に基づくリソース消費の定量化）

データ処理量が増えるごとに、CPU使用率も高くなり、メモリ使用量も増加します。

RowGroupSize

特殊変換

10,000

ない

データ件数
500
5,000
1万
10万
100万
200万

CPU使用率 メモリ使用量(MB) ※1
30 MB
7%
17%
97 MB
134 MB
20%
302 MB
21%
1400 MB
41%
2,505 MB
45%

時間(s)
4 s
46 s
74 s
38 s
334 s
1,004 s

※1本処理で使用されるメモリ量は、Workflow の yaml に定義されたテンプレートのリソース制限（resources.limits.memory など）に依存します。

設定された上限を超えた場合、メモリオーバーフロー（OOM）が発生し、Pod が強制終了される可能性があります。

・処理詳細

1　ツール起動

上記「起動パラメータ」仕様を参照して起動します。

＞　必要の引数が未設定の場合、

コンソールエラーメッセージ「必須オプション「xxxx」が未設定です。W/F動作時は定義YAMLテンプレートで引数に指定してください。」を表示して、ツール起動に失敗

> 排他の引数(-i/--input-file と --input-list-file と --input-file-selector)が同時設定の場合、

コンソールエラーメッセージ「オプション '-i/--input-file', '--input-list-file', '--input-file-selector' は同時に指定できません。どちらか一方のみを指定してください。」を表示して、ツール起動に失敗

2.　ツール初期処理

リネージグループ、サブグループ、ワークフローなどを初期化します。

リネージグループID、リネージサブグループIDで、バラメータyamlファイル名を決めて、

1/

改訂No. 削

13
13
13

13
13
13

4
4
4
5
4
4
4
4
4

4
4
4
4
4
4
4

12

12

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

・
・

「ワークフローID」　: 「リネージグループID + リネージサブグループID」
「parameter_(ワークフローID).yaml」

2.1　バラメータyaml設定内容の読込・チェック、リネージ情報の取得

ツール実行に必要なリネージ設定情報、各種パラメータを、事前に作成されたパラメータyamlファイルから、リネージの対応情報をリードします。

・パラメータyamlファイル(parameter_(ワークフローID).yaml)の存在チェック

> パラメータyaml(parameter_(ワークフローID).yaml) が見つかった場合、処理用のリネージ情報を取得します。

ツール実行用のリネージ設定内容をバラメータyamlから取得しておいて

ツール実行に必要なリネージIDを取得します。(バラメータyamlに、ワークフローのリネージサブグループにあるリネージ設定は全て入ってる)
・すべてのLineage情報の取得および設定パラメータの取得

パラメータyamlファイルを読込み、「ParameterInfoEntity」にキャシューします。

・処理リネージ(処理対象)の設定情報取得

処理リネージ(処理対象)の設定情報を取得するために、「リネージID(lineage_id)」が必要で、
ツールプロセスID、引数のタスクID(task_id)を使います。

> パラメータyaml(parameter_(ワークフローID).yaml) が見つからない場合、

エラーメッセージ「指定されたパラメータファイル「xxxx」が見つかりません。」を表示して、処理中断します。
※ログ出力の設定すらもないなので、コンソール画面にこのログを出力します。

2.2　ログ初期化、処理開始ログ出力およびDBログ出力

2.2.1 ログ初期化

共通の「LogUtility」を使用し、ログ出力に関する設定を初期化する。
あわせて、累積ツール固有のメッセージ定義ファイルを読み込み、ログメッセージのロードを行う。

パラメータ説明
パラメータ
LogUtilityConfig の構成

LogUtilityConfig の構成
項目
ProjectId
ExecuteTaskId
ProcessId
WorkFlowName
NameSpace
LocalLogFilePath
LogLevel
LogTypeList
ErrorHanding
MsgTemplatePathList

内容
ログ設定情報を含むLogUtilityConfig オブジェクト（下記を参照）

内容
GCPリソースを管理・操作する際に使用する、一意の識別子（ユニークID）
実行タスクID
プロセス識別用の一意なID
現在実行中のワークフロー名
ログ出力用のnamespace
ログファイルの出力パス
ログレベル（release, debug）
ログ出力先リスト（console, local, cloudlogging）
エラーハンドリングポリシー（例: resume, skip, terminate）
メッセージテンプレートファイルのパス

詳細は、LogUtilityのInitializer（LogUtilityConfig config)を参照する。

2.2.2 処理開始ログ出力

処理開始時に、開始ログおよびデータリネージの実行開始ログ（DBログ）を出力します。

出力内容
msgId
CI0001_AppStarted

メッセージテンプレート
「{0}」を開始します...

出力先：

説明
{0}: プログラム名(Process_Name)またはモジュール名

① 「データリネージ実行ログ」テーブル
② 「workflow_config.yml」ファイルに設定できて、LOG出力先は下記の3つ設定可能です。
コンソールにログを出力します。

-console

2/

6
6
6
6
6
6
6
6
6
6
6
8
8

6
12
6
6

13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13
13

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

-local
-cloud_logging

ローカルファイルにログを保存します。
CloudLogging 上にログを出力します。

詳細は、LogUtilityのInitLog(ExecuteLogEntity? executeLogEntity, string msgId, List<string> paramList)を参照する。

3 リネージIDに基づいて転記仕様yamlファイルの確定と読み込み

 指定されたリネージIDに基づき、対応する転記仕様YAMLファイル（transform_spec.(リネージID).yaml）を特定し、パースします。
※　ワークフローで使用する転記仕様 yaml ファイルは、Argo Workflows の artifacts 機能により、事前に共有・参照可能な状態となっています。

転記仕様yamlファイル（transform_spec_(リネージID).yaml）の内容を読み取っておいて

・転記仕様yamlファイルが見つかりました、

転記仕様yaml「transform_spec_(リネージID).yaml」を見て、このリネージで指定した転記情報を取得します。

・ 転記仕様yamlファイルが見つからないと

「転記仕様ファイル「xxxx」が見つかりません」とエラーメッセージを表示して、処理中断します。

4　入力、出力データファイルのレイアウト定義用スキーマyamlファイルのダウンロード

Input、Outputスキーマyamlファイルをダウンロードします。

パラメータyaml、転記仕様yamlから操作対象ファイルの定義情報を抽出し、指定GCSから、当該スキーマyamlファイルをダウンロードします。

まず、各スキーマyamlファイルの保存箇所を取得して、

バラメータyamlファイル(parameter_(ワークフローID).yaml)から、下記の情報を取得します：

・bucket: スキーマyamlファイルが保存されているGCSのバケット名。
ノード「setting_info」のサブノード「GCS」のサブノード「bucket」

・schemayamlpath: スキーマyamlファイルのパス。

ノード「setting_info」のサブノード「GCS」のサブノード「schemayamlpath」

 次に、対象のスキーマyamlファイル名を取得して

転記仕様yamlファイル(transform_spec_(リネージID).yaml)にから、下記の情報を取得します：

・Inputスキーマyamlファイル

ノード「input_file」の全てのサブノード「schemafilepath」

・Outputスキーマyamlファイル

ノード「output_file」の全てのサブノード「schemafilepath」

取得した bucket、schemayamlpath と Inputスキーマyamlファイル名、Outputスキーマyamlファイル名 を利用して、GCSから対象のスキーマyamlファイルをダウンロードします。

5　処理対象リスト作成

起動パラメータ（-i/--input-file または --process-unit-list-file）で指定された処理対象に対して、
本リネージの設定に基づきグループ化を行い、処理を実行します。

> パラメータ (-i/--input-file) だけを設定した場合

以下の処理を実行する：

・ 単一ファイルを対象リストに格納します。

> パラメータ (input-file-selector ) だけを設定した場合

以下の処理を実行する：

・ 処理対象を対象リストに格納します。

> パラメータ (--input-list-file) だけを設定した場合

以下の処理を実行する：

· JSON ファイルを読み込み、対象リストに格納します。

> -i/--input-file、--input-list-file、および input-file-selector のいずれも設定されていない場合

以下の処理を実行する：

・ 「repository 」と「filenamerule」に基づき、対象ファイルリストに格納します。

6　対象データファイルから、データをリードして、データコンバートを実行し、Parquetファイルを作成します。

データリード、データコンバート、Parquetファイルに書きこみの流れで実施します。

DownloadSchemaFile
パラメータ：

・転記仕様yaml
・ワークフロー設定情報

機能：

lineage で使用される可能性のある schema yaml ファイルのダウンロード

3/

13
13

13

8
8
7
7
7
7
7
7
7
12

5
5

5
5

4
4
3
3

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

6.1 Inputスキーマ、Outスキーマyamlファイルのリード

コンバート処理開始時に、InputスキーマyamlファイルおよびOutputスキーマyamlファイルを解析し、必要な情報を取得します。

① Inputスキーマyamlファイルの解析

・Before表現式の取得

special_transformノードに値が設定されている場合、そのカラムのBeforeに対応する辞書に表現式を格納します。

② Outputスキーマyamlファイルの解析

・Main/After表現式の取得

special_transformノードに値が設定されている場合、そのカラムのMain/Afterに対応する辞書に表現式を格納します。

・RowGroupKeyの取得

RowGroupKeyノードに値が設定されている場合、その値を取得し記録します。

・RowGroupSizeの取得

RowGroupSizeノードに値が設定されている場合、その値を取得し記録します。
RowGroupSizeノードに値が設定されていない場合、デフォルトのバッチ処理は次の条件で実行されます：

①、データが500MBのメモリを占有した場合（優先判定）
②、上記に該当せず、行数が1万行に達した場合

6.2　コールバック駆動のデータ取込・正規化（to Inputスキーマ）

データを行単位で読み込み、検証・正規化後、Inputスキーマ準拠レコードをコールバックで逐次返却する方式を定義します。

リネージの処理対処データソースファイルにより、使うプラグインを選んで処理します。
専用プラグインの指定があるかどうかを判定し、それに応じてデータファイルのロード処理を行います。

専用プラグインの指定取得:

「parameter_（ワークフローID）.yaml」ファイルに、リネージ「リネージID」ノードの「ExtendFunctionInfo1」の設定値で判断します。

・プラグインが指定された場合、プラグインの対象データファイルを読み込みます。

プラグインはデリゲートコールバック方式で動作するため、
データ読込む側では、以下のデリゲートを1つ提供する必要があります。

・onDataRow：処理済みのDataRowを受け取るデリゲート

詳細については、「プログラム基本設計書_プラグイン_振分モジュール_解析加工IF定義」を参照してください。

下記のデータタイプに対しては、それぞれのデータ形式やレイアウトに応じた専用プラグインを設計し、
デリゲートコールバック方式でデータを返すようにします。

・Excel
・PDF
・HTML
・Parquet
・TSV/CSV/固定長

←専用
←専用
←専用
←汎用、B145に実装します
←汎用、B145にテキストファイル解析プラグインとして実装します

※上記以外のデータタイプや解析形式を将来的に追加する場合は、専用プラグインを新規作成するだけで対応可能とします。

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

振分モジュールでは、指定された専用プラグインを起動するため、以下の引数を指定します：

・onDataRowデリゲート

・JSON形式の構造体

※JSON文字列には、以下の構造でデータ処理パイプラインの設定情報が含まれています。
ノード名
LineageGroupID
LineageSubGroupId
LineageId
LineageSummary
LineageReousceInfo

説明
リネージグループID

リネージサブグループID
リネージID
リネージ関連情報
リネージリソース情報

詳細内容
データ処理のリネージグループID
このデータパイプラインの子ワークフローIDです
呼び出し元のリネージ定義 LineageId
リネージのプラグイン、プロセス名称などの設定情報
入出力リソースのエンコーディング、入出力区分、圧縮方式などの設定情報

4/

6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
8
8
8

12
12

5

13
13
13
13

6
12

13
13

13
6
6
6
6
6
6
6

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

TransformyamlInfoDic
DataFileList
MacroVariable
WorkFlowSettings
EventFileContent

入力ファイル情報辞書
入力ファイルリスト
マクロ変数
ワークフロー設定情報
イベントファイル内容

入力ファイルのrepository、ファイル名称ルール、スキーマyaml名等設定情報
対象ファイルフルパスリスト
マクロ変数定義(マクロ変数名と正則表現)
ログ出力、GCSパス、作業・出力ディレクトリなど、ワークフロー実行に必要な設定
処理実行の契機となるイベント設定。ジョブ情報、通知先メールアドレス、通知API、などを含む。

・プラグインの設定がない場合、

設定不正として、エラーとして、累積ツールを異常終了（255）にします。
エラーログ：

「データリネージプロセス管理」で、当リネージID「{LineageID}」の「拡張機能情報1(extend_function_info_1)」が未設定です。

6.3　上記ロードできたデータレコードに対し、データコンバートをしてから、Parquetファイルに出力

メモリコストを控えるために、RowGroupSizeでメモリキャシューをしてから、データコンバート～Parquetファイル出力を行います。

6.3.1　Parquetファイル生成方式の分岐

OutputスキーマyamlファイルのRowGroupKey設定の有無によるParquetファイル生成方式の条件分け

・RowGroupKeyが設定されていない場合、直接Parquetファイルを生成
・RowGroupKeyが設定されている場合、DuckDBを経由してParquetファイルを生成

＞　RowGroupKeyを設定していない場合、直接Parquetファイルに出力

OutputスキーマyamlファイルのRowGroupSizeで、Parquetファイルに出力

1) データコンバート(入力レコード⇒出力レコードの変換)

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマカラム操作をして

「6.3.2　データコンバート方法」を参照してください。

2) Parquetファイル出力

上記データリスト(RowGroupSize)で、コンバートできたデータをParquetファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

＞　RowGroupKeyを設定している場合、DuckDBにキャシューして、Parquetファイルに出力

DuckDBへのデータ追加のバッチ処理は、次の条件で実行されます：

①、 データが500MBのメモリを達した場合（優先判定）
②、 上記に該当せず、行数が10万行に達した場合

・データコンバート

1) データコンバート(入力レコード⇒出力レコードの変換)

Inputスキーマカラム操作、転記仕様yamlのマッピング実施、Outputスキーマ操作をして

「6.3.2　データコンバート方法」を参照してください。

2) コンバートできたデータを DuckDB にインポート（ディスクベース）

対象の コンバートできたデータを DuckDB にインポートし、中間テーブルとして保存します。
メモリ上ではなく、ディスクベースで処理を行うことで、大容量データにも対応可能とします。

· Parquetファイル出力

指定RowGroupKeyで、Parquetファイルを生成

Outputスキーマyamlファイルに「RowGroupKey」の指定がある場合だけ、指定キーでもう一回グループして、Parquetファイルの生成を行います。

※データコンバートできたら、更にRowGroupKeyでグループする必要です。

1)　RowGroupKey によるグループ化処理

DuckDB 上のテーブルに対し、RowGroupKeyでデータをグループ化します。
グループ単位で再構成されたデータセットを、SQL を用いて取得・加工します。
※メモリコストを考慮した上で、実装する必要です。

2)　Parquetファイルの生成

＞　RowGroupSizeを設定している場合

※あくまで、現状の構造で推測した数値です。
　テスト&運用上で修正する必要かもしれません。

5/

6
6
6
6
6

5
9
9
12

5

7

7
7

7
7
7
7
7
7
7
8
8
8
7

7
7

7
7

7
7
7
7
7
7
7
7
7
7
7
7
7

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

RowGroupKey により分割された各グループ内で、 RowGroupSize 件数単位に分割。
分割されたデータごとに、Parquet ファイルに追加モードで出力します。

＞　RowGroupSizeを設定していない場合

RowGroupKey により分割されたデータごとに、Parquet ファイルに追加モードで出力します。

「6.3.3　Parquetファイル出力共通設定」を参照してください。

6.3.2　データコンバート方法

プラグインからonDataRow経由で受け取った各レコードを、指定された転記仕様YAMLに基づき、
リアルタイムでデータコンバートを実施します。

1)Inputスキーマyamlに、カラム表現式にBefore指定あり項目に対して、更にコンバートします。

元データに、ブリ処理をする必要か否かは、カラムの表現式にbefore計算式で記載してるので、

Inputスキーマyamlにカラム表現式に、「Before」変換式があるカラムに対し、指定表現式でコンバートを行う。

＞ Before表現式が設定ありカラム

カラム毎に、Beforeカラム表現式の操作をします。

※表現式の書き方は、下記2種類があります。 詳細は、「プログラム基本設計書_基礎-コンポーネント_ExpressionUtil」に参照

・expr

・expr_js

表現式の実装は自分で実装する必要です。

表現式の実行は、自分で実装する必要なし、規格に則った記述にすれば、JavaScript エンジンがその表現式を解釈し、実行してくれます。
Jint（ジント）は、.NET アプリケーション上で JavaScript を実行するための ECMAScript エンジン です。
C# など .NET 言語から JavaScript を呼び出して実行できる、軽量で高性能な JavaScript インタプリタです。

2) プリ処理できたレイアウトを出力レイアウトへのマッピングとデータ転送

コンバート処理が完了したデータは、出力レイアウトにマッピングしたら、データを転送する

Outputスキーマyamlファイルに設定された「ITEM_MATCH_MODE」に基づいて、入力解析結果のデータと出力レイアウトの間でカラムマッピング
※詳細は、ルールブックの「2. 入力ファイルと出力ファイルの列マッピングルール（ITEM_MATCH_MODE）」を参照。

3) Outputスキーマyamlに、カラム表現式にMain/After指定あり項目に対して、更にコンバートします。

Main/After変換辞書に記録されている各カラムおよび対応する表現式を使って、「Main→After」の順に変換を行う。

＞　Main/After表現式が設定されているカラム

・カラム毎に、Mainカラム表現式の操作をします。
・カラム毎に、Afterカラム表現式の操作をします。

6.3.3　Parquetファイル出力共通設定

Parquetファイルについて、出力方法と圧縮モードもバラメータyamlから取得して、

・出力処理方式（io_div）

GCSストリームにするか、ローカルに出力するかを判断します。
この io_divは、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード → 「io_div」ノードに設定しています。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「3-1　入出力区分（io_div）」を参照。

・論理圧縮（compress_method）

Parquetファイルの出力する際の論理圧縮方法を決定します。
論理圧縮の方法は、パラメータyamlファイルに、「lineage_info」ノード配下当該リネージIDノード配下の 「out」ノード→ 「compress_method」ノードに指定してます。

※詳細は、ルールブックのシート「3)DBの基本設定の説明」内の「5-5　圧縮方式(compress_method)」を参照。

7　作成できたParquetファイルの物理圧縮

物理圧縮指定有り場合、共通の圧縮方法を使って、Parquetファイルの圧縮を実施します。

共通「DwhFileProcessUtil」を利用して、出力ファイルを圧縮します。

6/

7
7
7
7
7
7

7

13
13

7
6
6
6
6
6
6
6
6
6
6
6
6
6

7
5
5
5
5
5
5
7
6
6
6
6
6
6

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

file:物理圧縮方法

圧縮なしの場合は、noneを設定しますか、空を設定します

設定内容
空白 または file:none
file:zip
file:7z
...

Parquet作成後の物理圧縮方法
圧縮しない
zip
7z
...

※物理圧縮の場合、パスワード指定有りの場合、暗号化かけて、圧縮します。

8　ログ出力（処理完了ログ／DB書込みログ）

処理の開始・終了・主要ステップ通過を標準化して記録し、「いつ／何の処理が／どの入力に対して／どう結果になったか」を追跡可能にします。
それで、異常時には、参照すべきログと特定手順が一意に分かることを目指すために、

8.1 処理完了ログ

処理完了時に、処理完了ログおよびデータリネージ実行完了ログ（DBログ）を出力します。

出力内容
msgId
区分
正常完了 CI0006_AppSuccess

メッセージテンプレート
「{0}」が正常完了しました。

異常終了 CI0007_AppFailure

「{0}」が異常終了しました。エラー内容: {1}

説明
{0}: プログラム名(Process_Name)またはモジュール名

{0}: プログラム名(Process_Name)またはモジュール名

{1}: 例外メッセージ（Exception.Message）

詳細は、LogUtilityのFinalLog(ExecuteLogEntity? executeLogEntity, string msgId, List<string> paramList, ExitCodes exitCode)を参照する。

8.2 logの例

ログタイトル：

2024/02/01 16:53:11 [情報] (NameSpace: ネームスペース WorkFlowName: ワークフロー名 ExecuteTaskId:実行タスクID)

ログ内容：

・基本な設定情報

リネージグループID、リネージID、PGID、execute_task_idなど

・ファイル情報

入出力ファイルパス、途中作成ファイル（パラメータyaml、転記仕様yaml）など情報

・設定情報のチェック結果
設定不正な情報

・開始、終了情報

各処理ステープの開始、終了情報、exit codeなど

例：

2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 実行時単位ID(リネージグループID-リネージID) :L00005
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツールID :acumulate-file-loader
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックを開始します...
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様スキーマ：D:\tmp\transform_spec.yml
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) ツール実行前チェックを行います...
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)
2024/02/01 16:53:11 [情報] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) yaml設定内容のチェックが正常完了しました。
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 転記仕様にoutfileのfilenameruleの設定が不正ため、下記のinfileに対しますoutfileの名称が重複になります。
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0001.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [エラー] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:)  ・t001_f0002_3321B0_11-03_001_parts_ver0002.html ⇒ 3321B0_11-03_parts_202311_ver001.Parquet
2024/02/01 16:53:11 [警告] (NameSpace: market-vehicle-data WorkFlowName: workflow-lg0013-130001-chlc9 ExecuteTaskId:) 累積処理が異常終了しました。(警告：99)

· 異常処理:

※詳細については、ルールブックのシート「2)WF定義」内の「8 DWH案件のエラー制御」をご参照ください。

7/

12
14
14
14
14
14
14

14

14

14

12

11

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

8/

Copyright(c) 2020 Broadleaf Co.,Ltd.

PTE-010-35.0303-01_プログラム基本設計書

